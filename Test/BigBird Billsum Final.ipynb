{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"BigBird Billsum Final.ipynb","provenance":[{"file_id":"10ssxMVREVpqhTY1JC73SAaWEgakZOxC0","timestamp":1635952407239},{"file_id":"1NvVBgDED8vinTcBGUP0xT1quUyEqp8aP","timestamp":1635891308251},{"file_id":"https://github.com/elsanns/xai-nlp-notebooks/blob/master/fine_tune_bart_summarization_two_langs.ipynb","timestamp":1635184568547}],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","name":"python3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"ee467af416034b0a81092ae165dcc425":{"model_module":"@jupyter-widgets/controls","model_name":"VBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_b278e5e6986640c692c6bce0d350c1b1","IPY_MODEL_63929b6c29a64778805539a33092a9b6"],"layout":"IPY_MODEL_a376cb3313674f6ab6a80dc76ae97eef"}},"b278e5e6986640c692c6bce0d350c1b1":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_21ef1768f55b44338651a12e80533e85","placeholder":"​","style":"IPY_MODEL_1228372610c948c6b671a961cfc97870","value":"1.090 MB of 1.090 MB uploaded (0.000 MB deduped)\r"}},"63929b6c29a64778805539a33092a9b6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_514208314d774803b64c7176a5336f29","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5521bb0023ed4f1db5387b485bc1f055","value":1}},"a376cb3313674f6ab6a80dc76ae97eef":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"21ef1768f55b44338651a12e80533e85":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1228372610c948c6b671a961cfc97870":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"514208314d774803b64c7176a5336f29":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5521bb0023ed4f1db5387b485bc1f055":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"X8VR8kd4ipPN"},"source":["\n","# Fine-tuning T5 Summarization\n","\n","---"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zImELPsbXADJ","executionInfo":{"elapsed":12,"status":"ok","timestamp":1649881780084,"user":{"displayName":"Jose Talavera","userId":"03337362936427322220"},"user_tz":300},"outputId":"c9fa13cb-902a-4c2e-b4f1-5eac12d45f68"},"source":["!nvidia-smi"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Wed Apr 13 20:29:39 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   36C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"markdown","metadata":{"id":"yUn2OqI9oPQb"},"source":["## Setup\n","\n","---"]},{"cell_type":"code","metadata":{"id":"pkzypz9I1O6H","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1649881784608,"user_tz":300,"elapsed":4528,"user":{"displayName":"Jose Talavera","userId":"03337362936427322220"}},"outputId":"ca5d907e-5905-4b56-9e21-1128e9ffd305"},"source":["!pip install ipywidgets\n","!jupyter nbextension enable --py widgetsnbextension"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: ipywidgets in /usr/local/lib/python3.7/dist-packages (7.7.0)\n","Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.7/dist-packages (from ipywidgets) (4.10.1)\n","Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets) (5.5.0)\n","Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.7/dist-packages (from ipywidgets) (5.1.1)\n","Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets) (3.6.0)\n","Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets) (1.1.0)\n","Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets) (5.3.0)\n","Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets) (0.2.0)\n","Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel>=4.5.1->ipywidgets) (5.1.1)\n","Requirement already satisfied: jupyter-client in /usr/local/lib/python3.7/dist-packages (from ipykernel>=4.5.1->ipywidgets) (5.3.5)\n","Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets) (4.8.0)\n","Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets) (0.8.1)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets) (2.6.1)\n","Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets) (1.0.18)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets) (4.4.2)\n","Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets) (57.4.0)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets) (0.7.5)\n","Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets) (4.3.3)\n","Requirement already satisfied: jupyter-core in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets) (4.9.2)\n","Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets) (2.15.3)\n","Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat>=4.2.0->ipywidgets) (5.6.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat>=4.2.0->ipywidgets) (4.1.1)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat>=4.2.0->ipywidgets) (4.11.3)\n","Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat>=4.2.0->ipywidgets) (0.18.1)\n","Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat>=4.2.0->ipywidgets) (21.4.0)\n","Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources>=1.4.0->jsonschema>=2.6->nbformat>=4.2.0->ipywidgets) (3.8.0)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0->ipywidgets) (1.15.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0->ipywidgets) (0.2.5)\n","Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.7/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets) (5.3.1)\n","Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.8.0)\n","Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (5.6.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.11.3)\n","Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.13.3)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets) (2.8.2)\n","Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets) (22.3.0)\n","Requirement already satisfied: ptyprocess in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.1->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.7.0)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.0.1)\n","Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.7.1)\n","Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.5.0)\n","Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.4)\n","Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.6.0)\n","Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (5.0.0)\n","Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.8.4)\n","Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.5.1)\n","Enabling notebook extension jupyter-js-widgets/extension...\n","Paths used for configuration of notebook: \n","    \t/root/.jupyter/nbconfig/notebook.json\n","      - Validating: \u001b[32mOK\u001b[0m\n","Paths used for configuration of notebook: \n","    \t/root/.jupyter/nbconfig/notebook.json\n"]}]},{"cell_type":"code","metadata":{"id":"_gaaojSBoQ5f","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1649881801262,"user_tz":300,"elapsed":16658,"user":{"displayName":"Jose Talavera","userId":"03337362936427322220"}},"outputId":"c3c2c7b6-4b17-4f9e-db41-01289af2dfe4"},"source":["! pip install transformers\n","! pip install datasets\n","! pip install sentencepiece\n","! pip install rouge_score\n","! pip install wandb"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.18.0)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.5.1)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.5)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.49)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.8)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.25.11)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: datasets in /usr/local/lib/python3.7/dist-packages (2.0.0)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets) (3.0.0)\n","Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.4)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.12.2)\n","Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.18.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets) (3.8.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.21.5)\n","Requirement already satisfied: pyarrow>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n","Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.5.1)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.64.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.11.3)\n","Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2022.3.0)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (4.1.1)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.6.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.25.11)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2021.10.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.0.2)\n","Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (0.13.0)\n","Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.0.12)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.3.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.2.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (6.0.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (21.4.0)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.7.2)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.8.0)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2018.9)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.96)\n","Requirement already satisfied: rouge_score in /usr/local/lib/python3.7/dist-packages (0.0.4)\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from rouge_score) (1.0.0)\n","Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from rouge_score) (1.15.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from rouge_score) (1.21.5)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from rouge_score) (3.2.5)\n","Requirement already satisfied: wandb in /usr/local/lib/python3.7/dist-packages (0.12.14)\n","Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.5.9)\n","Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n","Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (0.4.0)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (6.0)\n","Requirement already satisfied: GitPython>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.1.27)\n","Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n","Requirement already satisfied: shortuuid>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.0.8)\n","Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.8.2)\n","Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n","Requirement already satisfied: pathtools in /usr/local/lib/python3.7/dist-packages (from wandb) (0.1.2)\n","Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.17.3)\n","Requirement already satisfied: setproctitle in /usr/local/lib/python3.7/dist-packages (from wandb) (1.2.2)\n","Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n","Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (4.0.9)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (4.1.1)\n","Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (5.0.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (1.25.11)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2021.10.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n"]}]},{"cell_type":"code","metadata":{"id":"rimUDCQGoTAJ"},"source":["import torch\n","import numpy as np\n","import datasets\n","\n","from transformers import (\n","    AutoModelForSeq2SeqLM,\n","    AutoTokenizer,\n","    Seq2SeqTrainingArguments,\n","    Seq2SeqTrainer,\n","    DataCollatorForSeq2Seq,\n",")\n","\n","from tabulate import tabulate\n","import nltk\n","from datetime import datetime"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8zpflBQbzrvC","executionInfo":{"elapsed":2097,"status":"ok","timestamp":1649881811622,"user":{"displayName":"Jose Talavera","userId":"03337362936427322220"},"user_tz":300},"outputId":"db16e5a0-bb9a-4b6e-8303-031c2230857e"},"source":["WANDB_INTEGRATION = True\n","if WANDB_INTEGRATION:\n","    import wandb\n","\n","    wandb.login()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbigbam\u001b[0m (use `wandb login --relogin` to force relogin)\n"]}]},{"cell_type":"markdown","metadata":{"id":"aX-q_O-hoe3g"},"source":["## Model and tokenizer\n","\n","---"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VtEDrBTfwcEC","executionInfo":{"elapsed":5,"status":"ok","timestamp":1649881811623,"user":{"displayName":"Jose Talavera","userId":"03337362936427322220"},"user_tz":300},"outputId":"1102f5ff-c930-4469-b036-d51ba53a28f4"},"source":["import tensorflow as tf\n","print(tf.test.is_built_with_cuda())"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["True\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7vMhyyIPobyx","executionInfo":{"elapsed":10955,"status":"ok","timestamp":1649881822576,"user":{"displayName":"Jose Talavera","userId":"03337362936427322220"},"user_tz":300},"outputId":"d4bf43f6-d504-44f4-a3f0-0455e63e57cb"},"source":["from transformers import AutoTokenizer, AutoModelForPreTraining, AutoModelForSeq2SeqLM, AutoModelForMaskedLM\n","import torch\n","#Llamado del modelo\n","\n","# #Definición de modelo y tokenizador\n","tokenizer = AutoTokenizer.from_pretrained(\"google/bigbird-pegasus-large-arxiv\")\n","model = AutoModelForSeq2SeqLM.from_pretrained(\"google/bigbird-pegasus-large-arxiv\")\n","\n","# tokenizer = AutoTokenizer.from_pretrained(\"google/bigbird-roberta-base\")\n","# model = AutoModelForPreTraining.from_pretrained(\"google/bigbird-roberta-base\")\n","\n","# tokenizer = AutoTokenizer.from_pretrained(\"google/bigbird-roberta-large\")\n","# model = AutoModelForMaskedLM.from_pretrained(\"google/bigbird-roberta-large\")\n","\n","# Se fijan los parámetros del modelo\n","model.config.max_length = 500\n","model.config.min_length = 350\n","print(model.config)\n","\n","# tokenización\n","encoder_max_length = 256 \n","decoder_max_length = 128"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["BigBirdPegasusConfig {\n","  \"_name_or_path\": \"google/bigbird-pegasus-large-arxiv\",\n","  \"activation_dropout\": 0.0,\n","  \"activation_function\": \"gelu_new\",\n","  \"architectures\": [\n","    \"BigBirdPegasusForConditionalGeneration\"\n","  ],\n","  \"attention_dropout\": 0.0,\n","  \"attention_type\": \"block_sparse\",\n","  \"block_size\": 64,\n","  \"bos_token_id\": 2,\n","  \"classifier_dropout\": 0.0,\n","  \"d_model\": 1024,\n","  \"decoder_attention_heads\": 16,\n","  \"decoder_ffn_dim\": 4096,\n","  \"decoder_layerdrop\": 0.0,\n","  \"decoder_layers\": 16,\n","  \"decoder_start_token_id\": 2,\n","  \"dropout\": 0.1,\n","  \"encoder_attention_heads\": 16,\n","  \"encoder_ffn_dim\": 4096,\n","  \"encoder_layerdrop\": 0.0,\n","  \"encoder_layers\": 16,\n","  \"eos_token_id\": 1,\n","  \"gradient_checkpointing\": false,\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"length_penalty\": 0.8,\n","  \"max_length\": 500,\n","  \"max_position_embeddings\": 4096,\n","  \"min_length\": 350,\n","  \"model_type\": \"bigbird_pegasus\",\n","  \"num_beams\": 5,\n","  \"num_hidden_layers\": 16,\n","  \"num_random_blocks\": 3,\n","  \"pad_token_id\": 0,\n","  \"scale_embedding\": true,\n","  \"tokenizer_class\": \"PegasusTokenizer\",\n","  \"transformers_version\": \"4.18.0\",\n","  \"use_bias\": false,\n","  \"use_cache\": true,\n","  \"vocab_size\": 96103\n","}\n","\n"]}]},{"cell_type":"code","source":["print(tokenizer)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WExEQISSeDya","executionInfo":{"status":"ok","timestamp":1649881822576,"user_tz":300,"elapsed":14,"user":{"displayName":"Jose Talavera","userId":"03337362936427322220"}},"outputId":"d8dc5aa0-b3ef-4f07-b823-353817aaa0d4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["PreTrainedTokenizerFast(name_or_path='google/bigbird-pegasus-large-arxiv', vocab_size=96103, model_max_len=4096, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'eos_token': AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'unk_token': AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'sep_token': AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'pad_token': AddedToken(\"<pad>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'cls_token': AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'mask_token': AddedToken(\"[MASK]\", rstrip=False, lstrip=True, single_word=False, normalized=True)})\n"]}]},{"cell_type":"markdown","metadata":{"id":"wwtSPRJgomBS"},"source":["## Data\n","\n","---"]},{"cell_type":"markdown","metadata":{"id":"OZfrIK8fW9DU"},"source":["### Descarga y Preparación de los Datos"]},{"cell_type":"markdown","metadata":{"id":"t4MZ_LiNwI_T"},"source":["### Cargado de Dataset"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N0TPG-bEk-uU","executionInfo":{"elapsed":3726,"status":"ok","timestamp":1649881826292,"user":{"displayName":"Jose Talavera","userId":"03337362936427322220"},"user_tz":300},"outputId":"409e9f99-88aa-43d1-e858-cf9b1fd8f779"},"source":["train_data_txt = datasets.load_dataset(\"billsum\", '3.0.0', split=\"train[:1000]\")\n","validation_data_txt = datasets.load_dataset(\"billsum\", '3.0.0', split=\"test[:100]\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Using custom data configuration 3.0.0\n","Reusing dataset billsum (/root/.cache/huggingface/datasets/billsum/3.0.0/3.0.0/d1e95173aed3acb71327864be74ead49b578522e4c7206048b2f2e5351b57959)\n","Using custom data configuration 3.0.0\n","Reusing dataset billsum (/root/.cache/huggingface/datasets/billsum/3.0.0/3.0.0/d1e95173aed3acb71327864be74ead49b578522e4c7206048b2f2e5351b57959)\n"]}]},{"cell_type":"markdown","metadata":{"id":"5pbe750YpMfD"},"source":["**Preprocess and tokenize**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PyksYNwxA4OM","outputId":"6c9c0437-ec47-4f90-e798-6264ed48bcda","executionInfo":{"status":"ok","timestamp":1649881826292,"user_tz":300,"elapsed":11,"user":{"displayName":"Jose Talavera","userId":"03337362936427322220"}}},"source":["def batch_tokenize_preprocess(batch, tokenizer, max_source_length, max_target_length):\n","    source, target = batch[\"text\"], batch[\"summary\"]\n","    source_tokenized = tokenizer(\n","        source, padding=\"max_length\", truncation=True, max_length=max_source_length\n","    )\n","    target_tokenized = tokenizer(\n","        target, padding=\"max_length\", truncation=True, max_length=max_target_length\n","    )\n","\n","    batch = {k: v for k, v in source_tokenized.items()}\n","    # Ignore padding in the loss\n","    batch[\"labels\"] = [\n","        [-100 if token == tokenizer.pad_token_id else token for token in l]\n","        for l in target_tokenized[\"input_ids\"]\n","    ]\n","    return batch\n","\n","\n","train_data = train_data_txt.map(\n","    lambda batch: batch_tokenize_preprocess(\n","        batch, tokenizer, 10, 10\n","    ),\n","    batched=True,\n","    remove_columns=train_data_txt.column_names,\n",")\n","\n","validation_data = validation_data_txt.map(\n","    lambda batch: batch_tokenize_preprocess(\n","        batch, tokenizer, 10, 10\n","    ),\n","    batched=True,\n","    remove_columns=validation_data_txt.column_names,\n",")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Loading cached processed dataset at /root/.cache/huggingface/datasets/billsum/3.0.0/3.0.0/d1e95173aed3acb71327864be74ead49b578522e4c7206048b2f2e5351b57959/cache-3f636f53c3c3fd4b.arrow\n","Loading cached processed dataset at /root/.cache/huggingface/datasets/billsum/3.0.0/3.0.0/d1e95173aed3acb71327864be74ead49b578522e4c7206048b2f2e5351b57959/cache-126858f242e16f21.arrow\n"]}]},{"cell_type":"markdown","metadata":{"id":"h7ViBmMopWfb"},"source":["## Training\n","\n","---"]},{"cell_type":"markdown","metadata":{"id":"9EfTztMPv2vG"},"source":["### Metrics"]},{"cell_type":"code","metadata":{"id":"rpNCGl2sYl2p"},"source":["# Borrowed from https://github.com/huggingface/transformers/blob/master/examples/seq2seq/run_summarization.py\n","\n","nltk.download(\"punkt\", quiet=True)\n","\n","metric = datasets.load_metric(\"rouge\")\n","\n","\n","def postprocess_text(preds, labels):\n","    preds = [pred.strip() for pred in preds]\n","    labels = [label.strip() for label in labels]\n","\n","    # rougeLSum expects newline after each sentence\n","    preds = [\"\\n\".join(nltk.sent_tokenize(pred)) for pred in preds]\n","    labels = [\"\\n\".join(nltk.sent_tokenize(label)) for label in labels]\n","\n","    return preds, labels\n","\n","\n","def compute_metrics(eval_preds):\n","    preds, labels = eval_preds\n","    if isinstance(preds, tuple):\n","        preds = preds[0]\n","    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n","    # Replace -100 in the labels as we can't decode them.\n","    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n","    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n","\n","    # Some simple post-processing\n","    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n","\n","    result = metric.compute(\n","        predictions=decoded_preds, references=decoded_labels, use_stemmer=True\n","    )\n","    # Extract a few results from ROUGE\n","    result = {key: value.mid.fmeasure * 100 for key, value in result.items()}\n","\n","    prediction_lens = [\n","        np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds\n","    ]\n","    result[\"gen_len\"] = np.mean(prediction_lens)\n","    result = {k: round(v, 4) for k, v in result.items()}\n","    return result"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8O1EeUi-pbPA"},"source":["### Training arguments"]},{"cell_type":"code","metadata":{"id":"6R9d7ELIpX9F"},"source":["training_args = Seq2SeqTrainingArguments(\n","    output_dir=\"results\",\n","    num_train_epochs=10,  # demo\n","    do_train=True,\n","    do_eval=True,\n","    per_device_train_batch_size=2,  # demo\n","    per_device_eval_batch_size=2,\n","    learning_rate=3e-04,\n","    warmup_steps=500,\n","    weight_decay=0.1,\n","    label_smoothing_factor=0.1,\n","    predict_with_generate=True, #Para métricas ROUGE\n","    logging_dir=\"logs\",\n","    logging_steps=50,\n","    save_total_limit=3,\n",")\n","\n","data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n","\n","trainer = Seq2SeqTrainer(\n","    model=model,\n","    args=training_args,\n","    data_collator=data_collator,\n","    train_dataset=train_data,\n","    eval_dataset=validation_data,\n","    tokenizer=tokenizer,\n","    compute_metrics=compute_metrics,\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Qzcsz3gKplPO"},"source":["### Train"]},{"cell_type":"markdown","metadata":{"id":"Rpg2a0mfoD-l"},"source":["Wandb integration"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":69},"id":"tdaVPp9doF1c","executionInfo":{"elapsed":4205,"status":"ok","timestamp":1649881842289,"user":{"displayName":"Jose Talavera","userId":"03337362936427322220"},"user_tz":300},"outputId":"1ceb5ec2-ba8c-4e73-8265-5cdac23288ee"},"source":["if WANDB_INTEGRATION:\n","    wandb_run = wandb.init(\n","        project=\"BigBird_Billsum_FT\",\n","        config={\n","            \"per_device_train_batch_size\": training_args.per_device_train_batch_size,\n","            \"learning_rate\": training_args.learning_rate,\n","            \"dataset\": \"BillSum\",\n","        },\n","    )\n","\n","    now = datetime.now()\n","    current_time = now.strftime(\"%H%M%S\")\n","    wandb_run.name = \"run_\" + current_time"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.12.14"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20220413_203038-2za5blxx</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href=\"https://wandb.ai/bigbam/BigBird_Billsum_FT/runs/2za5blxx\" target=\"_blank\">absurd-grass-12</a></strong> to <a href=\"https://wandb.ai/bigbam/BigBird_Billsum_FT\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"]},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"kEtd_a7TPpkd"},"source":["Evaluate before fine-tuning"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":300},"id":"5yveDiz7pm3i","outputId":"448fe941-4c28-42b2-8459-239eaaec1d1c","executionInfo":{"status":"ok","timestamp":1649882365625,"user_tz":300,"elapsed":523347,"user":{"displayName":"Jose Talavera","userId":"03337362936427322220"}}},"source":["trainer.evaluate()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["***** Running Evaluation *****\n","  Num examples = 100\n","  Batch size = 2\n","Attention type 'block_sparse' is not possible if sequence_length: 10 <= num global tokens: 2 * config.block_size + min. num sliding tokens: 3 * config.block_size + config.num_random_blocks * config.block_size + additional buffer: config.num_random_blocks * config.block_size = 704 with config.block_size = 64, config.num_random_blocks = 3. Changing attention type to 'original_full'...\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [50/50 08:31]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"]},{"output_type":"execute_result","data":{"text/plain":["{'eval_gen_len': 498.57,\n"," 'eval_loss': 11.246406555175781,\n"," 'eval_rouge1': 0.7086,\n"," 'eval_rouge2': 0.0083,\n"," 'eval_rougeL': 0.7118,\n"," 'eval_rougeLsum': 0.7046,\n"," 'eval_runtime': 523.3183,\n"," 'eval_samples_per_second': 0.191,\n"," 'eval_steps_per_second': 0.096}"]},"metadata":{},"execution_count":14}]},{"cell_type":"markdown","metadata":{"id":"nkRb7hvgPrf2"},"source":["Train the model"]},{"cell_type":"code","metadata":{"id":"PZLM53u6mXyF"},"source":["torch.cuda.is_available()\n","import tensorflow as tf"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZgJsTMNan2cQ","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1649882365626,"user_tz":300,"elapsed":9,"user":{"displayName":"Jose Talavera","userId":"03337362936427322220"}},"outputId":"28edeab5-a763-456f-ac72-67926dac5478"},"source":["tf.test.gpu_device_name()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/device:GPU:0'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":16}]},{"cell_type":"code","metadata":{"id":"qYcYcbkr7ZZD","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1649883814821,"user_tz":300,"elapsed":1449203,"user":{"displayName":"Jose Talavera","userId":"03337362936427322220"}},"outputId":"bd7c561a-f72b-40d5-b386-d9079ea12006"},"source":["# %%wandb\n","# uncomment to display Wandb charts\n","\n","trainer.train()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","***** Running training *****\n","  Num examples = 1000\n","  Num Epochs = 10\n","  Instantaneous batch size per device = 2\n","  Total train batch size (w. parallel, distributed & accumulation) = 2\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 5000\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='5000' max='5000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [5000/5000 24:07, Epoch 10/10]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>50</td>\n","      <td>10.941200</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>9.153400</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>8.616900</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>8.297100</td>\n","    </tr>\n","    <tr>\n","      <td>250</td>\n","      <td>7.890500</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>7.274600</td>\n","    </tr>\n","    <tr>\n","      <td>350</td>\n","      <td>6.765500</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>6.244700</td>\n","    </tr>\n","    <tr>\n","      <td>450</td>\n","      <td>6.301500</td>\n","    </tr>\n","    <tr>\n","      <td>500</td>\n","      <td>6.304300</td>\n","    </tr>\n","    <tr>\n","      <td>550</td>\n","      <td>5.768900</td>\n","    </tr>\n","    <tr>\n","      <td>600</td>\n","      <td>5.673100</td>\n","    </tr>\n","    <tr>\n","      <td>650</td>\n","      <td>5.470300</td>\n","    </tr>\n","    <tr>\n","      <td>700</td>\n","      <td>5.263700</td>\n","    </tr>\n","    <tr>\n","      <td>750</td>\n","      <td>5.424900</td>\n","    </tr>\n","    <tr>\n","      <td>800</td>\n","      <td>5.248400</td>\n","    </tr>\n","    <tr>\n","      <td>850</td>\n","      <td>5.357000</td>\n","    </tr>\n","    <tr>\n","      <td>900</td>\n","      <td>5.344400</td>\n","    </tr>\n","    <tr>\n","      <td>950</td>\n","      <td>5.341900</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>5.122900</td>\n","    </tr>\n","    <tr>\n","      <td>1050</td>\n","      <td>4.889800</td>\n","    </tr>\n","    <tr>\n","      <td>1100</td>\n","      <td>4.860900</td>\n","    </tr>\n","    <tr>\n","      <td>1150</td>\n","      <td>4.933400</td>\n","    </tr>\n","    <tr>\n","      <td>1200</td>\n","      <td>4.919900</td>\n","    </tr>\n","    <tr>\n","      <td>1250</td>\n","      <td>4.995300</td>\n","    </tr>\n","    <tr>\n","      <td>1300</td>\n","      <td>4.803500</td>\n","    </tr>\n","    <tr>\n","      <td>1350</td>\n","      <td>4.873700</td>\n","    </tr>\n","    <tr>\n","      <td>1400</td>\n","      <td>4.968400</td>\n","    </tr>\n","    <tr>\n","      <td>1450</td>\n","      <td>4.980100</td>\n","    </tr>\n","    <tr>\n","      <td>1500</td>\n","      <td>4.704500</td>\n","    </tr>\n","    <tr>\n","      <td>1550</td>\n","      <td>4.636700</td>\n","    </tr>\n","    <tr>\n","      <td>1600</td>\n","      <td>4.583500</td>\n","    </tr>\n","    <tr>\n","      <td>1650</td>\n","      <td>4.630300</td>\n","    </tr>\n","    <tr>\n","      <td>1700</td>\n","      <td>4.477400</td>\n","    </tr>\n","    <tr>\n","      <td>1750</td>\n","      <td>4.568100</td>\n","    </tr>\n","    <tr>\n","      <td>1800</td>\n","      <td>4.444500</td>\n","    </tr>\n","    <tr>\n","      <td>1850</td>\n","      <td>4.501500</td>\n","    </tr>\n","    <tr>\n","      <td>1900</td>\n","      <td>4.453500</td>\n","    </tr>\n","    <tr>\n","      <td>1950</td>\n","      <td>4.449700</td>\n","    </tr>\n","    <tr>\n","      <td>2000</td>\n","      <td>4.718800</td>\n","    </tr>\n","    <tr>\n","      <td>2050</td>\n","      <td>4.068800</td>\n","    </tr>\n","    <tr>\n","      <td>2100</td>\n","      <td>4.141800</td>\n","    </tr>\n","    <tr>\n","      <td>2150</td>\n","      <td>4.408800</td>\n","    </tr>\n","    <tr>\n","      <td>2200</td>\n","      <td>4.240300</td>\n","    </tr>\n","    <tr>\n","      <td>2250</td>\n","      <td>4.215200</td>\n","    </tr>\n","    <tr>\n","      <td>2300</td>\n","      <td>4.357800</td>\n","    </tr>\n","    <tr>\n","      <td>2350</td>\n","      <td>4.166800</td>\n","    </tr>\n","    <tr>\n","      <td>2400</td>\n","      <td>4.283400</td>\n","    </tr>\n","    <tr>\n","      <td>2450</td>\n","      <td>4.281300</td>\n","    </tr>\n","    <tr>\n","      <td>2500</td>\n","      <td>4.231500</td>\n","    </tr>\n","    <tr>\n","      <td>2550</td>\n","      <td>3.944000</td>\n","    </tr>\n","    <tr>\n","      <td>2600</td>\n","      <td>3.919000</td>\n","    </tr>\n","    <tr>\n","      <td>2650</td>\n","      <td>4.163700</td>\n","    </tr>\n","    <tr>\n","      <td>2700</td>\n","      <td>4.091000</td>\n","    </tr>\n","    <tr>\n","      <td>2750</td>\n","      <td>4.088700</td>\n","    </tr>\n","    <tr>\n","      <td>2800</td>\n","      <td>3.960600</td>\n","    </tr>\n","    <tr>\n","      <td>2850</td>\n","      <td>3.937300</td>\n","    </tr>\n","    <tr>\n","      <td>2900</td>\n","      <td>4.009700</td>\n","    </tr>\n","    <tr>\n","      <td>2950</td>\n","      <td>3.992500</td>\n","    </tr>\n","    <tr>\n","      <td>3000</td>\n","      <td>3.982700</td>\n","    </tr>\n","    <tr>\n","      <td>3050</td>\n","      <td>3.740200</td>\n","    </tr>\n","    <tr>\n","      <td>3100</td>\n","      <td>3.624800</td>\n","    </tr>\n","    <tr>\n","      <td>3150</td>\n","      <td>3.724600</td>\n","    </tr>\n","    <tr>\n","      <td>3200</td>\n","      <td>3.846600</td>\n","    </tr>\n","    <tr>\n","      <td>3250</td>\n","      <td>3.871000</td>\n","    </tr>\n","    <tr>\n","      <td>3300</td>\n","      <td>3.758800</td>\n","    </tr>\n","    <tr>\n","      <td>3350</td>\n","      <td>3.872300</td>\n","    </tr>\n","    <tr>\n","      <td>3400</td>\n","      <td>3.760300</td>\n","    </tr>\n","    <tr>\n","      <td>3450</td>\n","      <td>3.636800</td>\n","    </tr>\n","    <tr>\n","      <td>3500</td>\n","      <td>4.037300</td>\n","    </tr>\n","    <tr>\n","      <td>3550</td>\n","      <td>3.649700</td>\n","    </tr>\n","    <tr>\n","      <td>3600</td>\n","      <td>3.670600</td>\n","    </tr>\n","    <tr>\n","      <td>3650</td>\n","      <td>3.525300</td>\n","    </tr>\n","    <tr>\n","      <td>3700</td>\n","      <td>3.677200</td>\n","    </tr>\n","    <tr>\n","      <td>3750</td>\n","      <td>3.503600</td>\n","    </tr>\n","    <tr>\n","      <td>3800</td>\n","      <td>3.613900</td>\n","    </tr>\n","    <tr>\n","      <td>3850</td>\n","      <td>3.562100</td>\n","    </tr>\n","    <tr>\n","      <td>3900</td>\n","      <td>3.673100</td>\n","    </tr>\n","    <tr>\n","      <td>3950</td>\n","      <td>3.518500</td>\n","    </tr>\n","    <tr>\n","      <td>4000</td>\n","      <td>3.641500</td>\n","    </tr>\n","    <tr>\n","      <td>4050</td>\n","      <td>3.473600</td>\n","    </tr>\n","    <tr>\n","      <td>4100</td>\n","      <td>3.369900</td>\n","    </tr>\n","    <tr>\n","      <td>4150</td>\n","      <td>3.365300</td>\n","    </tr>\n","    <tr>\n","      <td>4200</td>\n","      <td>3.523900</td>\n","    </tr>\n","    <tr>\n","      <td>4250</td>\n","      <td>3.440600</td>\n","    </tr>\n","    <tr>\n","      <td>4300</td>\n","      <td>3.454600</td>\n","    </tr>\n","    <tr>\n","      <td>4350</td>\n","      <td>3.457200</td>\n","    </tr>\n","    <tr>\n","      <td>4400</td>\n","      <td>3.467700</td>\n","    </tr>\n","    <tr>\n","      <td>4450</td>\n","      <td>3.509700</td>\n","    </tr>\n","    <tr>\n","      <td>4500</td>\n","      <td>3.557900</td>\n","    </tr>\n","    <tr>\n","      <td>4550</td>\n","      <td>3.351400</td>\n","    </tr>\n","    <tr>\n","      <td>4600</td>\n","      <td>3.480600</td>\n","    </tr>\n","    <tr>\n","      <td>4650</td>\n","      <td>3.413800</td>\n","    </tr>\n","    <tr>\n","      <td>4700</td>\n","      <td>3.316500</td>\n","    </tr>\n","    <tr>\n","      <td>4750</td>\n","      <td>3.438900</td>\n","    </tr>\n","    <tr>\n","      <td>4800</td>\n","      <td>3.336200</td>\n","    </tr>\n","    <tr>\n","      <td>4850</td>\n","      <td>3.277500</td>\n","    </tr>\n","    <tr>\n","      <td>4900</td>\n","      <td>3.352000</td>\n","    </tr>\n","    <tr>\n","      <td>4950</td>\n","      <td>3.348700</td>\n","    </tr>\n","    <tr>\n","      <td>5000</td>\n","      <td>3.267400</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Saving model checkpoint to results/checkpoint-500\n","Configuration saved in results/checkpoint-500/config.json\n","Model weights saved in results/checkpoint-500/pytorch_model.bin\n","tokenizer config file saved in results/checkpoint-500/tokenizer_config.json\n","Special tokens file saved in results/checkpoint-500/special_tokens_map.json\n","Deleting older checkpoint [results/checkpoint-4000] due to args.save_total_limit\n","Saving model checkpoint to results/checkpoint-1000\n","Configuration saved in results/checkpoint-1000/config.json\n","Model weights saved in results/checkpoint-1000/pytorch_model.bin\n","tokenizer config file saved in results/checkpoint-1000/tokenizer_config.json\n","Special tokens file saved in results/checkpoint-1000/special_tokens_map.json\n","Deleting older checkpoint [results/checkpoint-4500] due to args.save_total_limit\n","Saving model checkpoint to results/checkpoint-1500\n","Configuration saved in results/checkpoint-1500/config.json\n","Model weights saved in results/checkpoint-1500/pytorch_model.bin\n","tokenizer config file saved in results/checkpoint-1500/tokenizer_config.json\n","Special tokens file saved in results/checkpoint-1500/special_tokens_map.json\n","Deleting older checkpoint [results/checkpoint-5000] due to args.save_total_limit\n","Saving model checkpoint to results/checkpoint-2000\n","Configuration saved in results/checkpoint-2000/config.json\n","Model weights saved in results/checkpoint-2000/pytorch_model.bin\n","tokenizer config file saved in results/checkpoint-2000/tokenizer_config.json\n","Special tokens file saved in results/checkpoint-2000/special_tokens_map.json\n","Deleting older checkpoint [results/checkpoint-500] due to args.save_total_limit\n","Saving model checkpoint to results/checkpoint-2500\n","Configuration saved in results/checkpoint-2500/config.json\n","Model weights saved in results/checkpoint-2500/pytorch_model.bin\n","tokenizer config file saved in results/checkpoint-2500/tokenizer_config.json\n","Special tokens file saved in results/checkpoint-2500/special_tokens_map.json\n","Deleting older checkpoint [results/checkpoint-1000] due to args.save_total_limit\n","Saving model checkpoint to results/checkpoint-3000\n","Configuration saved in results/checkpoint-3000/config.json\n","Model weights saved in results/checkpoint-3000/pytorch_model.bin\n","tokenizer config file saved in results/checkpoint-3000/tokenizer_config.json\n","Special tokens file saved in results/checkpoint-3000/special_tokens_map.json\n","Deleting older checkpoint [results/checkpoint-1500] due to args.save_total_limit\n","Saving model checkpoint to results/checkpoint-3500\n","Configuration saved in results/checkpoint-3500/config.json\n","Model weights saved in results/checkpoint-3500/pytorch_model.bin\n","tokenizer config file saved in results/checkpoint-3500/tokenizer_config.json\n","Special tokens file saved in results/checkpoint-3500/special_tokens_map.json\n","Deleting older checkpoint [results/checkpoint-2000] due to args.save_total_limit\n","Saving model checkpoint to results/checkpoint-4000\n","Configuration saved in results/checkpoint-4000/config.json\n","Model weights saved in results/checkpoint-4000/pytorch_model.bin\n","tokenizer config file saved in results/checkpoint-4000/tokenizer_config.json\n","Special tokens file saved in results/checkpoint-4000/special_tokens_map.json\n","Deleting older checkpoint [results/checkpoint-2500] due to args.save_total_limit\n","Saving model checkpoint to results/checkpoint-4500\n","Configuration saved in results/checkpoint-4500/config.json\n","Model weights saved in results/checkpoint-4500/pytorch_model.bin\n","tokenizer config file saved in results/checkpoint-4500/tokenizer_config.json\n","Special tokens file saved in results/checkpoint-4500/special_tokens_map.json\n","Deleting older checkpoint [results/checkpoint-3000] due to args.save_total_limit\n","Saving model checkpoint to results/checkpoint-5000\n","Configuration saved in results/checkpoint-5000/config.json\n","Model weights saved in results/checkpoint-5000/pytorch_model.bin\n","tokenizer config file saved in results/checkpoint-5000/tokenizer_config.json\n","Special tokens file saved in results/checkpoint-5000/special_tokens_map.json\n","Deleting older checkpoint [results/checkpoint-3500] due to args.save_total_limit\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n"]},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=5000, training_loss=4.5079508392333985, metrics={'train_runtime': 1447.9641, 'train_samples_per_second': 6.906, 'train_steps_per_second': 3.453, 'total_flos': 282056294400000.0, 'train_loss': 4.5079508392333985, 'epoch': 10.0})"]},"metadata":{},"execution_count":17}]},{"cell_type":"markdown","metadata":{"id":"V3C-4SfOPssY"},"source":["Evaluate after fine-tuning"]},{"cell_type":"markdown","source":[""],"metadata":{"id":"ipiBgr4dzx-T"}},{"cell_type":"code","metadata":{"id":"_-QyUtCRH9DO","colab":{"base_uri":"https://localhost:8080/","height":263},"executionInfo":{"status":"ok","timestamp":1649884187123,"user_tz":300,"elapsed":372316,"user":{"displayName":"Jose Talavera","userId":"03337362936427322220"}},"outputId":"a307542f-4289-4dc3-88f2-6ceb5ba1819a"},"source":["trainer.evaluate()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["***** Running Evaluation *****\n","  Num examples = 100\n","  Batch size = 2\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='100' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [50/50 38:52]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["{'epoch': 10.0,\n"," 'eval_gen_len': 351.79,\n"," 'eval_loss': 6.039236068725586,\n"," 'eval_rouge1': 2.7213,\n"," 'eval_rouge2': 0.5139,\n"," 'eval_rougeL': 2.2297,\n"," 'eval_rougeLsum': 2.6067,\n"," 'eval_runtime': 372.1941,\n"," 'eval_samples_per_second': 0.269,\n"," 'eval_steps_per_second': 0.134}"]},"metadata":{},"execution_count":18}]},{"cell_type":"code","metadata":{"id":"ClRTrG2ETUm3","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["ee467af416034b0a81092ae165dcc425","b278e5e6986640c692c6bce0d350c1b1","63929b6c29a64778805539a33092a9b6","a376cb3313674f6ab6a80dc76ae97eef","21ef1768f55b44338651a12e80533e85","1228372610c948c6b671a961cfc97870","514208314d774803b64c7176a5336f29","5521bb0023ed4f1db5387b485bc1f055"]},"executionInfo":{"status":"ok","timestamp":1649884192280,"user_tz":300,"elapsed":5169,"user":{"displayName":"Jose Talavera","userId":"03337362936427322220"}},"outputId":"0b6c27be-7996-4188-f58d-86324c7ce6be"},"source":["if WANDB_INTEGRATION:\n","    wandb_run.finish()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ee467af416034b0a81092ae165dcc425"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/gen_len</td><td>█▁</td></tr><tr><td>eval/loss</td><td>█▁</td></tr><tr><td>eval/rouge1</td><td>▁█</td></tr><tr><td>eval/rouge2</td><td>▁█</td></tr><tr><td>eval/rougeL</td><td>▁█</td></tr><tr><td>eval/rougeLsum</td><td>▁█</td></tr><tr><td>eval/runtime</td><td>█▁</td></tr><tr><td>eval/samples_per_second</td><td>▁█</td></tr><tr><td>eval/steps_per_second</td><td>▁█</td></tr><tr><td>train/epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>train/learning_rate</td><td>▂▃▅▇███▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▁▁▁</td></tr><tr><td>train/loss</td><td>█▆▅▄▃▃▃▃▂▃▂▃▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/gen_len</td><td>351.79</td></tr><tr><td>eval/loss</td><td>6.03924</td></tr><tr><td>eval/rouge1</td><td>2.7213</td></tr><tr><td>eval/rouge2</td><td>0.5139</td></tr><tr><td>eval/rougeL</td><td>2.2297</td></tr><tr><td>eval/rougeLsum</td><td>2.6067</td></tr><tr><td>eval/runtime</td><td>372.1941</td></tr><tr><td>eval/samples_per_second</td><td>0.269</td></tr><tr><td>eval/steps_per_second</td><td>0.134</td></tr><tr><td>train/epoch</td><td>10.0</td></tr><tr><td>train/global_step</td><td>5000</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>3.2674</td></tr><tr><td>train/total_flos</td><td>282056294400000.0</td></tr><tr><td>train/train_loss</td><td>4.50795</td></tr><tr><td>train/train_runtime</td><td>1447.9641</td></tr><tr><td>train/train_samples_per_second</td><td>6.906</td></tr><tr><td>train/train_steps_per_second</td><td>3.453</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Synced <strong style=\"color:#cdcd00\">absurd-grass-12</strong>: <a href=\"https://wandb.ai/bigbam/BigBird_Billsum_FT/runs/2za5blxx\" target=\"_blank\">https://wandb.ai/bigbam/BigBird_Billsum_FT/runs/2za5blxx</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20220413_203038-2za5blxx/logs</code>"]},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"-gSLVnGL9bol"},"source":["## Evaluation\n","\n","---"]},{"cell_type":"markdown","metadata":{"id":"hDwj24cfILS6"},"source":["**Generate summaries from the fine-tuned model and compare them with those generated from the original, pre-trained one.**"]},{"cell_type":"code","metadata":{"id":"NV64-XdA_rOM","colab":{"base_uri":"https://localhost:8080/","height":450},"executionInfo":{"status":"error","timestamp":1649884198543,"user_tz":300,"elapsed":6265,"user":{"displayName":"Jose Talavera","userId":"03337362936427322220"}},"outputId":"12e15904-ba50-407c-b17f-361010c9c8d2"},"source":["from transformers import BigBirdTokenizer, BigBirdModel\n","import torch\n","def generate_summary(test_samples, model):\n","    inputs = tokenizer(\n","        test_samples[\"text\"],\n","        padding=\"max_length\",\n","        truncation=True,\n","        max_length=encoder_max_length,\n","        return_tensors=\"pt\",\n","    )\n","    input_ids = inputs.input_ids.to(model.device)\n","    attention_mask = inputs.attention_mask.to(model.device)\n","    outputs = model.generate(input_ids, attention_mask=attention_mask)\n","    output_str = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n","    return outputs, output_str\n","\n","\n","test_samples = validation_data_txt.select(range(16))\n","\n","summaries_after_tuning = generate_summary(test_samples, model)[1]\n","\n"],"execution_count":null,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-20-de6b634db7e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mtest_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidation_data_txt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0msummaries_after_tuning\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-20-de6b634db7e7>\u001b[0m in \u001b[0;36mgenerate_summary\u001b[0;34m(test_samples, model)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0minput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mattention_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0moutput_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_str\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/generation_utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, max_length, min_length, do_sample, early_stopping, num_beams, temperature, top_k, top_p, typical_p, repetition_penalty, bad_words_ids, force_words_ids, bos_token_id, pad_token_id, eos_token_id, length_penalty, no_repeat_ngram_size, encoder_no_repeat_ngram_size, num_return_sequences, max_time, max_new_tokens, decoder_start_token_id, use_cache, num_beam_groups, diversity_penalty, prefix_allowed_tokens_fn, logits_processor, stopping_criteria, constraints, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, forced_bos_token_id, forced_eos_token_id, remove_invalid_values, synced_gpus, exponential_decay_length_penalty, **model_kwargs)\u001b[0m\n\u001b[1;32m   1323\u001b[0m                 \u001b[0mreturn_dict_in_generate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict_in_generate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m                 \u001b[0msynced_gpus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynced_gpus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1325\u001b[0;31m                 \u001b[0;34m**\u001b[0m\u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1326\u001b[0m             )\n\u001b[1;32m   1327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/generation_utils.py\u001b[0m in \u001b[0;36mbeam_search\u001b[0;34m(self, input_ids, beam_scorer, logits_processor, stopping_criteria, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[1;32m   2160\u001b[0m                 \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2161\u001b[0m                 \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2162\u001b[0;31m                 \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2163\u001b[0m             )\n\u001b[1;32m   2164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bigbird_pegasus/modeling_bigbird_pegasus.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   2560\u001b[0m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2561\u001b[0m         )\n\u001b[0;32m-> 2562\u001b[0;31m         \u001b[0mlm_logits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlm_head\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinal_logits_bias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2564\u001b[0m         \u001b[0mmasked_lm_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1846\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1847\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 30.00 MiB (GPU 0; 15.90 GiB total capacity; 14.28 GiB already allocated; 31.75 MiB free; 14.76 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"]}]},{"cell_type":"code","source":["# model_before_tuning =  AutoModelForSeq2SeqLM.from_pretrained(\"google/bigbird-pegasus-large-arxiv\")\n","# summaries_before_tuning = generate_summary(test_samples, model_before_tuning)[1]\n","\n","model_before_tuning = ['in a recent letter to the editor of _ physica a _, a. s. aquilar, a. a. de oliveira, j. a. de oliveira, m. a. de oliveira, j. a. de oliveira, s. a. de oliveira, e. a. de oliveira, s. a. de oliveira, c. m. de oliveira, f. a. de oliveira, s. a. de oliveira, s. a. de oliveira, j. a. de oliveira, s. a. de oliveira, e. a. de oliveira, s. a. de oliveira, s. a. de oliveira, s. a. de oliveira, s. a. de oliveira, s. a. de oliveira, s. a. de oliveira, s. a. de oliveira, s. a. de oliveira, s. a. de oliveira, s. a. de olive',\n"," 'this may be cited as : 1.. <n> ( a). : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : ',\n"," 'in this letter, we express our deepest gratitude to the people of the united states of america for their decades of dedicated service to our country and to the world.<n> in addition, we express our deepest gratitude to the people of the united states of america for their decades of dedicated service to our country and to the world.',\n"," 'we address here the question of whether or not the city of manchester has the right to require that any candidate for mayor be a citizen of manchester.<n> we also address the question of whether or not the city has the right to demand that any candidate for mayor be a citizen of manchester.',\n"," 'we address the following question : 1. for a finite period of time ( 180 days ).<n> 2. for a finite period of time ( 45 days ).<n> 3. for a finite period of time ( 180 days ).<n> 4. for a finite period of time ( 45 days ).<n> 5. for a finite period of time ( 180 days ).<n> 6. for a finite period of time ( 45 days ).<n> 7. for a finite period of time ( 180 days ).<n> 8. for a finite period of time ( 45 days ).<n> 9. for a finite period of time ( 180 days ).<n> 10. for a finite period of time ( 45 days ).<n> 11. for a finite period of time ( 180 days ).<n> 12. for a finite period of time ( 45 days ).<n> 14. for a finite period of time ( 180 days ).<n> 15. for a finite period of time ( 45 days ).<n> 16. for a finite period of time (',\n"," 'we address the following question : under what conditions can a controlled substance program be established and maintained?.<n> the answer is : under what conditions can a controlled substance program be established and maintained?.<n> the program is defined by : ( i ) the number of patients for which a controlled substance has been prescribed, ( ii ) the number of patients for which a controlled substance has been administered, and ( iii ) the total number of patients for which a controlled substance has been administered.<n> the program is defined by : ( i ) the number of patients for which a controlled substance has been prescribed, ( ii ) the number of patients for which a controlled substance has been administered, and ( iii ) the total number of patients for which a controlled substance has been administered.<n> the program is defined by : ( i ) the number of patients for which a controlled substance has been prescribed, ( ii ) the number of patients for which a controlled substance has been administered, and ( iii ) the total number of patients for which a controlled substance has been administered.<n> the program is defined by : ( i ) the number of patients for which',\n"," 'in this brief report, we present the results of our study of the water cycle in the earth s mantle.<n> we show that the water cycle in the mantle of the earth can be divided into two parts.<n> the first part is adiabatic.<n> the second part is non - adiabatic.<n> we show that the water cycle in the mantle of the earth can be divided into two parts.<n> the first part is adiabatic.<n> the second part is non - adiabatic. in this report, we present the results of our study of the water cycle in the earth s mantle.<n> we show that the water cycle in the mantle of the earth can be divided into two parts.<n> the first part is adiabatic.<n> the second part is non - adiabatic.<n> we show that the water cycle in the mantle of the earth can be divided into two parts.<n> the first part is adiabatic.<n> the second part is non - adiabatic. in this report, we present the results of our study of the water cycle in the earth s mantle.<n> we',\n"," \"in this brief note, we point out a flaw in the definition of  supercritical '' in eq.2(a ). in eq.2(b ), the definition of  supercritical '' in eq.2(a ) is as follows : in the definition of  supercritical '',  a supercritical point '' is defined as the point where the difference between the critical point and the value of the critical point is less than the critical point itself.  in eq.2(a ), the supercritical point is defined as the point at which the value of the critical point is equal to the critical point itself.  in eq.2(b ), the supercritical point is defined as the point at which the value of the critical point is equal to the critical point itself.  in eq.2(c ), the supercritical point is defined as the point at which the value of the critical point is equal to the critical point itself.  in eq.(d ), the supercritical point is defined as the point at which the value of the critical point is equal to\",\n"," 'the following report was submitted to the editor of _ american journal of physics _ : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : :',\n"," 'the tribe refers to a consumer who order(s ) smokeless product by means of voice or other method, or to a consumer who order(s ) smokeless product by means of mail or other method, or to a consumer who order(s ) smokeless product by use of a common carrier, or to a consumer who order(s ) smokeless product by use of a common carrier, or to a consumer who order(s ) smokeless product by use of a common carrier.<n> the tribe is divided into two parts.<n> the first part refers to the tribe which is located at the state of virginia.<n> the second part refers to the tribe located at the state of new york.<n> the state of virginia is divided into two parts. in the state of new york, the state of virginia is divided into two parts. in the state of new york, the state of virginia is divided into two parts. in the state of new york, the state of virginia is divided into two parts. in the state of new york, the state of virginia is divided into two parts. in the state of new york ',\n"," 'in this brief report, we address some of the questions raised in @xcite and @xcite, as well as in @xcite and @xcite.',\n"," 'in this brief report, we summarize the results of our analysis of the dna assembly at the sloan digital sky survey ( sdss ) facility.<n> we find that : _ ( i ) _ dna assembly at the sdss facility is successful ; _ ( ii ) _ dna assembly at the sdss facility is successful ; _ ( iii ) _ dna assembly at the sdss facility is successful ; _ ( iv ) _ dna assembly at the sdss facility is successful ; _ ( v ) _ dna assembly at the sdss facility is successful ; _ ( vi ) _ dna assembly at the sdss facility is successful ; _ ( vi ) _ dna assembly at the sdss facility is successful ; _ ( v ) _ dna assembly at the sdss facility is successful ; _ ( vi ) _ dna assembly at the sdss facility is successful ; _ ( vi ',\n"," 'a higher education accrediting agency ( haa ) has recently determined that there is a conflict of interest in the accrediting process of a single institution.<n> this is because the haa has determined that there is a conflict between the accrediting requirements of the institution and those of an independent accrediting agency.<n> the conflict of interest arises because the haa has determined that there is a conflict of interest between the accrediting requirements of the institution and those of an independent accrediting agency.<n> the conflict of interest arises because the haa has determined that there is a conflict of interest between the accrediting requirements of the institution and those of an independent accrediting agency.<n> the conflict of interest arises because the haa has determined that there is a conflict of interest between the accrediting requirements of the institution and those of an independent accrediting agency.<n> the conflict of interest arises because the haa has determined that there is a conflict of interest between the accrediting requirements of the institution and those of an independent accrediting agency.<n> the conflict of interest arises because the haa has determined that there is a conflict of interest between the accrediting requirements of the institution and those of an independent accrediting agency.<n> the conflict of interest arises',\n"," 'hydrogen is one of the most abundant elements in the universe. yet it is also one of the least abundant.<n> hydrogen is the most abundant element in the universe.<n> the reason for this is twofold.<n> first, hydrogen is the most abundant element in the universe.<n> second, hydrogen is also one of the least abundant.<n> there are many reasons for hydrogen being the least abundant element in the universe.<n> the reason is twofold.<n> first, hydrogen is the most abundant element in the universe.<n> there are many reasons for hydrogen being the least abundant element in the universe.<n> there are many reasons for hydrogen being the least abundant element in the universe.<n> there are many reasons for hydrogen being the least abundant element in the universe.<n> there are many reasons for hydrogen being the least abundant element in the universe.<n> there are many reasons for hydrogen being the least abundant element in the universe.<n> there are many reasons for hydrogen being the least abundant element in the universe.<n> there are many reasons for hydrogen being the least abundant element in the universe.<n> there are many reasons for hydrogen being the least abundant element in the universe.<n> there are many reasons for',\n"," 'based on a recent report of a high level of elevated levels of mercury in the atmosphere of the kingfish, a request has been made to the government of the commonwealth of hawaii for the establishment of a laboratory for the assessment of the levels of mercury present in the atmosphere of the kingfish. the laboratory for the assessment of the levels of mercury present in the atmosphere of the kingfish, based on a recent report of a high level of elevated levels of mercury in the atmosphere of the kingfish, a request has been made to the government of the commonwealth of hawaii for the establishment of a laboratory for the assessment of the levels of mercury present in the atmosphere of the kingfish. _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ',\n"," 'we report the results of a study of the effects of heavy elements on the stability of a heavy - ion collision ( hic ) site.<n> the study was performed as part of the hic legacy research program for the national institute of standards and technology ( nimt ) in the context of the heavy - ion collision ( hic ) modeling and prediction.<n> heavy - ion collision ( hic ) is one of the most important problems in the field of heavy - ion collision ( hic ) physics.<n> the hic is characterized by a large number of phenomena, including : formation and propagation of : ( i ) fragments ; ( ii ) nuclei ; ( iii ) secondary nuclei ; ( iv ) secondary nuclei ; ( v ) secondary nuclei ; ( vi ) secondary nuclei ; ( vii ) secondary nuclei ; ( vi ) secondary nuclei ; ( v ) secondary nuclei ; ( vi ) secondary nuclei ; ( vii ) secondary nuclei ; ( vi ) secondary nuclei ; ( viii ) secondary nuclei ; ( vi ) secondary nuclei ; ( vii )']"],"metadata":{"id":"NSK4uSAyk0J0"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dLiP9Q5QWg-A"},"source":["summaries_before_tuning"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"D7IPtJLjCcmS"},"source":["print(\n","    tabulate(\n","        zip(\n","            range(len(summaries_after_tuning)),\n","            summaries_after_tuning,\n","        ),\n","        headers=[\"Id\", \"Summary after\"],\n","    )\n",")\n","print(\"\\nTarget summaries:\\n\")\n","print(\n","    tabulate(list(enumerate(test_samples[\"summary\"])), headers=[\"Id\", \"Target summary\"])\n",")\n","print(\"\\nSource documents:\\n\")\n","print(tabulate(list(enumerate(test_samples[\"text\"])), headers=[\"Id\", \"Document\"]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"qPngkTTznDFv"},"execution_count":null,"outputs":[]}]}