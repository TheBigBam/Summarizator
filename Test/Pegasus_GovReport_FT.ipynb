{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Pegasus_GovReport_FT.ipynb","provenance":[{"file_id":"10ssxMVREVpqhTY1JC73SAaWEgakZOxC0","timestamp":1647118585184},{"file_id":"1NvVBgDED8vinTcBGUP0xT1quUyEqp8aP","timestamp":1635891308251},{"file_id":"https://github.com/elsanns/xai-nlp-notebooks/blob/master/fine_tune_bart_summarization_two_langs.ipynb","timestamp":1635184568547}],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","name":"python3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"e60ac31cbc744727a0fc6e2ef9582e21":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_959b7523255349ad844bf2e2a2afabee","IPY_MODEL_c23a3bd3eff34e3092ef489063d2a596","IPY_MODEL_49222058a0f54683a6eb69024b2d69b8"],"layout":"IPY_MODEL_2bb22b12e45c431a936a85dc445a2ad2"}},"959b7523255349ad844bf2e2a2afabee":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d657f7b35ed9492ab5a4bc82b50018f1","placeholder":"​","style":"IPY_MODEL_b58b9d9652dd44b0914fd8b26cd6ba96","value":"100%"}},"c23a3bd3eff34e3092ef489063d2a596":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ec8960bb2536418784fb1f133250b4a2","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f90965cf0dfd4f20849be819c2022c8f","value":1}},"49222058a0f54683a6eb69024b2d69b8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_92eae19382e740428a8a4e897044e6bb","placeholder":"​","style":"IPY_MODEL_4c917c1734804011910564fb37878b38","value":" 1/1 [00:06&lt;00:00,  6.34s/ba]"}},"2bb22b12e45c431a936a85dc445a2ad2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d657f7b35ed9492ab5a4bc82b50018f1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b58b9d9652dd44b0914fd8b26cd6ba96":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ec8960bb2536418784fb1f133250b4a2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f90965cf0dfd4f20849be819c2022c8f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"92eae19382e740428a8a4e897044e6bb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4c917c1734804011910564fb37878b38":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"592ffcb578214a49ae2c30e8cd7639bd":{"model_module":"@jupyter-widgets/controls","model_name":"VBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_a041807bec27471eaf486e3880553dce","IPY_MODEL_f2800ba3df5c4412aadfae94306c7247"],"layout":"IPY_MODEL_f2db0f1bd83948848a4ca862741dbbce"}},"a041807bec27471eaf486e3880553dce":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4e866bff80ea42c8ae2c11ef32c1d539","placeholder":"​","style":"IPY_MODEL_12f0870792ca44adb0c964d1187aaea5","value":"1.523 MB of 1.523 MB uploaded (0.000 MB deduped)\r"}},"f2800ba3df5c4412aadfae94306c7247":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_b275ac404fb0446893e2da778c5f65f4","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f4938ad8354d4738b3bad96e14086671","value":1}},"f2db0f1bd83948848a4ca862741dbbce":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4e866bff80ea42c8ae2c11ef32c1d539":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"12f0870792ca44adb0c964d1187aaea5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b275ac404fb0446893e2da778c5f65f4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f4938ad8354d4738b3bad96e14086671":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"X8VR8kd4ipPN"},"source":["\n","# Fine-tuning Pegasus Summarization\n","\n","---"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zImELPsbXADJ","executionInfo":{"status":"ok","timestamp":1649773800722,"user_tz":300,"elapsed":6,"user":{"displayName":"Jose Talavera","userId":"03337362936427322220"}},"outputId":"d89ad067-8af8-40d6-bbf8-003cbdb24122"},"source":["!nvidia-smi"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Tue Apr 12 14:30:01 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   70C    P0    30W /  70W |      0MiB / 15109MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"markdown","metadata":{"id":"yUn2OqI9oPQb"},"source":["## Setup\n","\n","---"]},{"cell_type":"code","metadata":{"id":"pkzypz9I1O6H","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1649773803794,"user_tz":300,"elapsed":3075,"user":{"displayName":"Jose Talavera","userId":"03337362936427322220"}},"outputId":"2243739a-516f-4e4b-dd16-3b0dd7c4c20b"},"source":["!pip install ipywidgets\n","!jupyter nbextension enable --py widgetsnbextension"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: ipywidgets in /usr/local/lib/python3.7/dist-packages (7.7.0)\n","Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets) (5.2.0)\n","Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets) (5.5.0)\n","Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.7/dist-packages (from ipywidgets) (5.1.1)\n","Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets) (1.1.0)\n","Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.7/dist-packages (from ipywidgets) (4.10.1)\n","Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets) (3.6.0)\n","Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets) (0.2.0)\n","Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel>=4.5.1->ipywidgets) (5.1.1)\n","Requirement already satisfied: jupyter-client in /usr/local/lib/python3.7/dist-packages (from ipykernel>=4.5.1->ipywidgets) (5.3.5)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets) (2.6.1)\n","Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets) (57.4.0)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets) (0.7.5)\n","Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets) (4.8.0)\n","Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets) (1.0.18)\n","Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets) (0.8.1)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets) (4.4.2)\n","Requirement already satisfied: jupyter-core in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets) (4.9.2)\n","Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets) (4.3.3)\n","Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (21.4.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (3.10.0.2)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (4.11.3)\n","Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (0.18.1)\n","Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (5.4.0)\n","Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources>=1.4.0->jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (3.7.0)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0->ipywidgets) (1.15.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0->ipywidgets) (0.2.5)\n","Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.7/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets) (5.3.1)\n","Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.13.3)\n","Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.8.0)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.11.3)\n","Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (5.6.1)\n","Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets) (22.3.0)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets) (2.8.2)\n","Requirement already satisfied: ptyprocess in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.1->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.7.0)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.0.1)\n","Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.6.0)\n","Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.4)\n","Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.1.0)\n","Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.5.0)\n","Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.8.4)\n","Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.7.1)\n","Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.5.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (21.3)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.0.7)\n","Enabling notebook extension jupyter-js-widgets/extension...\n","Paths used for configuration of notebook: \n","    \t/root/.jupyter/nbconfig/notebook.json\n","      - Validating: \u001b[32mOK\u001b[0m\n","Paths used for configuration of notebook: \n","    \t/root/.jupyter/nbconfig/notebook.json\n"]}]},{"cell_type":"code","metadata":{"id":"_gaaojSBoQ5f","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1649773820796,"user_tz":300,"elapsed":17006,"user":{"displayName":"Jose Talavera","userId":"03337362936427322220"}},"outputId":"2c935e1d-1bbf-4379-fead-f0c6a4adf41a"},"source":["! pip install transformers\n","! pip install datasets\n","! pip install sentencepiece\n","! pip install rouge_score\n","! pip install wandb"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.18.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.11.6)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.49)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.5.1)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.63.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.5)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.25.11)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: datasets in /usr/local/lib/python3.7/dist-packages (2.0.0)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.12.2)\n","Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.18.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.21.5)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets) (3.8.1)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets) (3.0.0)\n","Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.5.1)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n","Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2022.3.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\n","Requirement already satisfied: pyarrow>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.11.3)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.63.0)\n","Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.4)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.10.0.2)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.6.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2021.10.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.25.11)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.3.0)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.0.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (21.4.0)\n","Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (0.13.0)\n","Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.0.12)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (6.0.2)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.7.2)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.7.0)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2018.9)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.96)\n","Requirement already satisfied: rouge_score in /usr/local/lib/python3.7/dist-packages (0.0.4)\n","Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from rouge_score) (1.15.0)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from rouge_score) (3.2.5)\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from rouge_score) (1.0.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from rouge_score) (1.21.5)\n","Requirement already satisfied: wandb in /usr/local/lib/python3.7/dist-packages (0.12.14)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (6.0)\n","Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (0.4.0)\n","Requirement already satisfied: shortuuid>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.0.8)\n","Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n","Requirement already satisfied: GitPython>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.1.27)\n","Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.8.2)\n","Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n","Requirement already satisfied: setproctitle in /usr/local/lib/python3.7/dist-packages (from wandb) (1.2.2)\n","Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.5.9)\n","Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n","Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n","Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n","Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.17.3)\n","Requirement already satisfied: pathtools in /usr/local/lib/python3.7/dist-packages (from wandb) (0.1.2)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (4.0.9)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (3.10.0.2)\n","Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (5.0.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2021.10.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (1.25.11)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n"]}]},{"cell_type":"code","metadata":{"id":"rimUDCQGoTAJ"},"source":["import torch\n","import numpy as np\n","import datasets\n","\n","from transformers import (\n","    AutoModelForSeq2SeqLM,\n","    AutoTokenizer,\n","    Seq2SeqTrainingArguments,\n","    Seq2SeqTrainer,\n","    DataCollatorForSeq2Seq,\n",")\n","\n","from tabulate import tabulate\n","import nltk\n","from datetime import datetime"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8zpflBQbzrvC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1649773826714,"user_tz":300,"elapsed":2275,"user":{"displayName":"Jose Talavera","userId":"03337362936427322220"}},"outputId":"372e5483-646c-45e3-fb38-948a045c242d"},"source":["WANDB_INTEGRATION = True\n","if WANDB_INTEGRATION:\n","    import wandb\n","\n","    wandb.login()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbigbam\u001b[0m (use `wandb login --relogin` to force relogin)\n"]}]},{"cell_type":"markdown","metadata":{"id":"aX-q_O-hoe3g"},"source":["## Model and tokenizer\n","\n","---"]},{"cell_type":"markdown","metadata":{"id":"yb21WY-9mavn"},"source":["Hiperparámetros: \n","\n","[HF Bart configuration](https://huggingface.co/transformers/_modules/transformers/configuration_bart.html)\n","\n","[Fairseq Bart](https://github.com/pytorch/fairseq/tree/master/examples/bart)"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VtEDrBTfwcEC","executionInfo":{"status":"ok","timestamp":1649773826714,"user_tz":300,"elapsed":5,"user":{"displayName":"Jose Talavera","userId":"03337362936427322220"}},"outputId":"9b151fc6-2e99-4ff0-c3ab-1ee57a9a0550"},"source":["import tensorflow as tf\n","print(tf.test.is_built_with_cuda())"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["True\n"]}]},{"cell_type":"code","metadata":{"id":"7vMhyyIPobyx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1649773849077,"user_tz":300,"elapsed":22365,"user":{"displayName":"Jose Talavera","userId":"03337362936427322220"}},"outputId":"a8f8ae2d-a45c-47c7-e8b7-ce3b29114d49"},"source":["#Llamado del modelo\n","# model_name = \"sshleifer/distill-pegasus-xsum-16-8\"\n","model_name = \"google/pegasus-billsum\"\n","#Definición de modelo y tokenizador\n","model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","\n","# Se fijan los parámetros del modelo\n","model.config.activation_dropout = 0.0\n","model.config.max_length=500\n","model.config.min_length=350\n","print(model.config)\n","\n","# tokenización\n","encoder_max_length = 256 \n","decoder_max_length = 64"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["PegasusConfig {\n","  \"_name_or_path\": \"google/pegasus-billsum\",\n","  \"activation_dropout\": 0.0,\n","  \"activation_function\": \"relu\",\n","  \"add_bias_logits\": false,\n","  \"add_final_layer_norm\": true,\n","  \"architectures\": [\n","    \"PegasusForConditionalGeneration\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classif_dropout\": 0.0,\n","  \"classifier_dropout\": 0.0,\n","  \"d_model\": 1024,\n","  \"decoder_attention_heads\": 16,\n","  \"decoder_ffn_dim\": 4096,\n","  \"decoder_layerdrop\": 0.0,\n","  \"decoder_layers\": 16,\n","  \"decoder_start_token_id\": 0,\n","  \"dropout\": 0.1,\n","  \"encoder_attention_heads\": 16,\n","  \"encoder_ffn_dim\": 4096,\n","  \"encoder_layerdrop\": 0.0,\n","  \"encoder_layers\": 16,\n","  \"eos_token_id\": 1,\n","  \"extra_pos_embeddings\": 1,\n","  \"forced_eos_token_id\": 1,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"length_penalty\": 0.6,\n","  \"max_length\": 500,\n","  \"max_position_embeddings\": 1024,\n","  \"min_length\": 350,\n","  \"model_type\": \"pegasus\",\n","  \"normalize_before\": true,\n","  \"normalize_embedding\": false,\n","  \"num_beams\": 8,\n","  \"num_hidden_layers\": 16,\n","  \"pad_token_id\": 0,\n","  \"scale_embedding\": true,\n","  \"static_position_embeddings\": true,\n","  \"transformers_version\": \"4.18.0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 96103\n","}\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"wwtSPRJgomBS"},"source":["## Data\n","\n","---"]},{"cell_type":"markdown","metadata":{"id":"OZfrIK8fW9DU"},"source":["### Descarga y Preparación de los Datos"]},{"cell_type":"markdown","metadata":{"id":"t4MZ_LiNwI_T"},"source":["### Cargado de Dataset"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N0TPG-bEk-uU","executionInfo":{"status":"ok","timestamp":1649773855148,"user_tz":300,"elapsed":6080,"user":{"displayName":"Jose Talavera","userId":"03337362936427322220"}},"outputId":"179b7b2a-178f-4df3-81df-82a65c2cbaf9"},"source":["train_data_txt = datasets.load_dataset(\"ccdv/govreport-summarization\", split=\"train[:5000]\")\n","validation_data_txt = datasets.load_dataset(\"ccdv/govreport-summarization\", split=\"test[:500]\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["No config specified, defaulting to: gov_report_summarization_dataset/document\n","Reusing dataset gov_report_summarization_dataset (/root/.cache/huggingface/datasets/ccdv___gov_report_summarization_dataset/document/1.0.0/32c7f04ec577e9dc99b889eff9d64a321a3a00b7332e8733eb32d39bebbdc34f)\n","No config specified, defaulting to: gov_report_summarization_dataset/document\n","Reusing dataset gov_report_summarization_dataset (/root/.cache/huggingface/datasets/ccdv___gov_report_summarization_dataset/document/1.0.0/32c7f04ec577e9dc99b889eff9d64a321a3a00b7332e8733eb32d39bebbdc34f)\n"]}]},{"cell_type":"markdown","metadata":{"id":"5pbe750YpMfD"},"source":["**Preprocess and tokenize**"]},{"cell_type":"code","metadata":{"id":"PyksYNwxA4OM","colab":{"base_uri":"https://localhost:8080/","height":66,"referenced_widgets":["e60ac31cbc744727a0fc6e2ef9582e21","959b7523255349ad844bf2e2a2afabee","c23a3bd3eff34e3092ef489063d2a596","49222058a0f54683a6eb69024b2d69b8","2bb22b12e45c431a936a85dc445a2ad2","d657f7b35ed9492ab5a4bc82b50018f1","b58b9d9652dd44b0914fd8b26cd6ba96","ec8960bb2536418784fb1f133250b4a2","f90965cf0dfd4f20849be819c2022c8f","92eae19382e740428a8a4e897044e6bb","4c917c1734804011910564fb37878b38"]},"executionInfo":{"status":"ok","timestamp":1649773861670,"user_tz":300,"elapsed":6530,"user":{"displayName":"Jose Talavera","userId":"03337362936427322220"}},"outputId":"4b0ae050-1786-4d4c-a9d5-35890f7b1a56"},"source":["def batch_tokenize_preprocess(batch, tokenizer, max_source_length, max_target_length):\n","    source, target = batch[\"report\"], batch[\"summary\"]\n","    source_tokenized = tokenizer(\n","        source, padding=\"max_length\", truncation=True, max_length=max_source_length\n","    )\n","    target_tokenized = tokenizer(\n","        target, padding=\"max_length\", truncation=True, max_length=max_target_length\n","    )\n","\n","    batch = {k: v for k, v in source_tokenized.items()}\n","    # Ignore padding in the loss\n","    batch[\"labels\"] = [\n","        [-100 if token == tokenizer.pad_token_id else token for token in l]\n","        for l in target_tokenized[\"input_ids\"]\n","    ]\n","    return batch\n","\n","\n","train_data = train_data_txt.map(\n","    lambda batch: batch_tokenize_preprocess(\n","        batch, tokenizer, encoder_max_length, decoder_max_length\n","    ),\n","    batched=True,\n","    remove_columns=train_data_txt.column_names,\n",")\n","\n","validation_data = validation_data_txt.map(\n","    lambda batch: batch_tokenize_preprocess(\n","        batch, tokenizer, encoder_max_length, decoder_max_length\n","    ),\n","    batched=True,\n","    remove_columns=validation_data_txt.column_names,\n",")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Loading cached processed dataset at /root/.cache/huggingface/datasets/ccdv___gov_report_summarization_dataset/document/1.0.0/32c7f04ec577e9dc99b889eff9d64a321a3a00b7332e8733eb32d39bebbdc34f/cache-16d9cb613c820a67.arrow\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/1 [00:00<?, ?ba/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e60ac31cbc744727a0fc6e2ef9582e21"}},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"h7ViBmMopWfb"},"source":["## Training\n","\n","---"]},{"cell_type":"markdown","metadata":{"id":"9EfTztMPv2vG"},"source":["### Metrics"]},{"cell_type":"code","metadata":{"id":"rpNCGl2sYl2p"},"source":["# Borrowed from https://github.com/huggingface/transformers/blob/master/examples/seq2seq/run_summarization.py\n","\n","nltk.download(\"punkt\", quiet=True)\n","\n","metric = datasets.load_metric(\"rouge\")\n","\n","\n","def postprocess_text(preds, labels):\n","    preds = [pred.strip() for pred in preds]\n","    labels = [label.strip() for label in labels]\n","\n","    # rougeLSum expects newline after each sentence\n","    preds = [\"\\n\".join(nltk.sent_tokenize(pred)) for pred in preds]\n","    labels = [\"\\n\".join(nltk.sent_tokenize(label)) for label in labels]\n","\n","    return preds, labels\n","\n","\n","def compute_metrics(eval_preds):\n","    preds, labels = eval_preds\n","    if isinstance(preds, tuple):\n","        preds = preds[0]\n","    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n","    # Replace -100 in the labels as we can't decode them.\n","    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n","    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n","\n","    # Some simple post-processing\n","    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n","\n","    result = metric.compute(\n","        predictions=decoded_preds, references=decoded_labels, use_stemmer=True\n","    )\n","    # Extract a few results from ROUGE\n","    result = {key: value.mid.fmeasure * 100 for key, value in result.items()}\n","\n","    prediction_lens = [\n","        np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds\n","    ]\n","    result[\"gen_len\"] = np.mean(prediction_lens)\n","    result = {k: round(v, 4) for k, v in result.items()}\n","    return result"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8O1EeUi-pbPA"},"source":["### Training arguments"]},{"cell_type":"code","metadata":{"id":"6R9d7ELIpX9F"},"source":["training_args = Seq2SeqTrainingArguments(\n","    output_dir=\"results\",\n","    num_train_epochs=8,  # demo\n","    do_train=True,\n","    # do_eval=True,\n","    per_device_train_batch_size=2,  # demo\n","    per_device_eval_batch_size=2,\n","    learning_rate=3e-04,\n","    warmup_steps=1000,\n","    weight_decay=0.1,\n","    label_smoothing_factor=0.1,\n","    predict_with_generate=True, #Para métricas ROUGE\n","    logging_dir=\"logs\",\n","    logging_steps=1000,\n","    save_total_limit=3,\n",")\n","\n","data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n","\n","trainer = Seq2SeqTrainer(\n","    model=model,\n","    args=training_args,\n","    data_collator=data_collator,\n","    train_dataset=train_data,\n","    eval_dataset=validation_data,\n","    tokenizer=tokenizer,\n","    compute_metrics=compute_metrics,\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Nueva sección"],"metadata":{"id":"L5xr3APzK_FA"}},{"cell_type":"markdown","metadata":{"id":"Qzcsz3gKplPO"},"source":["### Train"]},{"cell_type":"markdown","metadata":{"id":"Rpg2a0mfoD-l"},"source":["Wandb integration"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ns6c0cMuWDXp","executionInfo":{"status":"ok","timestamp":1649773868517,"user_tz":300,"elapsed":20,"user":{"displayName":"Jose Talavera","userId":"03337362936427322220"}},"outputId":"95d60a4a-515d-4b47-9abd-8412bb2d86c8"},"source":["wandb"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<module 'wandb' from '/usr/local/lib/python3.7/dist-packages/wandb/__init__.py'>"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"tdaVPp9doF1c","colab":{"base_uri":"https://localhost:8080/","height":69},"executionInfo":{"status":"ok","timestamp":1649773872492,"user_tz":300,"elapsed":3993,"user":{"displayName":"Jose Talavera","userId":"03337362936427322220"}},"outputId":"6a9ca8a1-0a05-40b6-bed0-3761aa90393b"},"source":["if WANDB_INTEGRATION:\n","    wandb_run = wandb.init(\n","        project=\"distill-Googlepegasus_govreport_FT\",\n","        config={\n","            \"per_device_train_batch_size\": training_args.per_device_train_batch_size,\n","            \"learning_rate\": training_args.learning_rate,\n","            \"dataset\": \"govreport\",\n","        },\n","    )\n","\n","    now = datetime.now()\n","    current_time = now.strftime(\"%H%M%S\")\n","    wandb_run.name = \"run_\" + current_time"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.12.14"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20220412_143108-d3eqwv74</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href=\"https://wandb.ai/bigbam/distill-Googlepegasus_govreport_FT/runs/d3eqwv74\" target=\"_blank\">crimson-planet-6</a></strong> to <a href=\"https://wandb.ai/bigbam/distill-Googlepegasus_govreport_FT\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"]},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"kEtd_a7TPpkd"},"source":["Evaluate before fine-tuning"]},{"cell_type":"code","metadata":{"id":"5yveDiz7pm3i","colab":{"base_uri":"https://localhost:8080/","height":263},"outputId":"ecdd5a30-9f50-4f23-e952-4204eb54a457","executionInfo":{"status":"ok","timestamp":1649778360354,"user_tz":300,"elapsed":4487873,"user":{"displayName":"Jose Talavera","userId":"03337362936427322220"}}},"source":["trainer.evaluate()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["***** Running Evaluation *****\n","  Num examples = 500\n","  Batch size = 2\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='250' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [250/250 1:14:11]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"]},{"output_type":"execute_result","data":{"text/plain":["{'eval_gen_len': 468.3,\n"," 'eval_loss': 5.9050397872924805,\n"," 'eval_rouge1': 12.3556,\n"," 'eval_rouge2': 3.0414,\n"," 'eval_rougeL': 8.6666,\n"," 'eval_rougeLsum': 10.7723,\n"," 'eval_runtime': 4487.7108,\n"," 'eval_samples_per_second': 0.111,\n"," 'eval_steps_per_second': 0.056}"]},"metadata":{},"execution_count":14}]},{"cell_type":"markdown","metadata":{"id":"nkRb7hvgPrf2"},"source":["Train the model"]},{"cell_type":"code","metadata":{"id":"PZLM53u6mXyF"},"source":["torch.cuda.is_available()\n","import tensorflow as tf"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZgJsTMNan2cQ","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1649778360963,"user_tz":300,"elapsed":6,"user":{"displayName":"Jose Talavera","userId":"03337362936427322220"}},"outputId":"06af247b-ffe9-42ff-de47-a24d4f589b73"},"source":["tf.test.gpu_device_name()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/device:GPU:0'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":16}]},{"cell_type":"code","metadata":{"id":"qYcYcbkr7ZZD","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1649792042594,"user_tz":300,"elapsed":13681636,"user":{"displayName":"Jose Talavera","userId":"03337362936427322220"}},"outputId":"05e99e12-a244-4de1-a30a-276d77c357e6"},"source":["#%%wandb\n","# uncomment to display Wandb charts\n","\n","trainer.train()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","***** Running training *****\n","  Num examples = 5000\n","  Num Epochs = 8\n","  Instantaneous batch size per device = 2\n","  Total train batch size (w. parallel, distributed & accumulation) = 2\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 20000\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='20000' max='20000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [20000/20000 3:48:01, Epoch 8/8]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1000</td>\n","      <td>4.254100</td>\n","    </tr>\n","    <tr>\n","      <td>2000</td>\n","      <td>3.863900</td>\n","    </tr>\n","    <tr>\n","      <td>3000</td>\n","      <td>3.544200</td>\n","    </tr>\n","    <tr>\n","      <td>4000</td>\n","      <td>3.301700</td>\n","    </tr>\n","    <tr>\n","      <td>5000</td>\n","      <td>3.318900</td>\n","    </tr>\n","    <tr>\n","      <td>6000</td>\n","      <td>2.829300</td>\n","    </tr>\n","    <tr>\n","      <td>7000</td>\n","      <td>2.864400</td>\n","    </tr>\n","    <tr>\n","      <td>8000</td>\n","      <td>2.654500</td>\n","    </tr>\n","    <tr>\n","      <td>9000</td>\n","      <td>2.491500</td>\n","    </tr>\n","    <tr>\n","      <td>10000</td>\n","      <td>2.503400</td>\n","    </tr>\n","    <tr>\n","      <td>11000</td>\n","      <td>2.190700</td>\n","    </tr>\n","    <tr>\n","      <td>12000</td>\n","      <td>2.225200</td>\n","    </tr>\n","    <tr>\n","      <td>13000</td>\n","      <td>2.100100</td>\n","    </tr>\n","    <tr>\n","      <td>14000</td>\n","      <td>2.003800</td>\n","    </tr>\n","    <tr>\n","      <td>15000</td>\n","      <td>2.011200</td>\n","    </tr>\n","    <tr>\n","      <td>16000</td>\n","      <td>1.870400</td>\n","    </tr>\n","    <tr>\n","      <td>17000</td>\n","      <td>1.862100</td>\n","    </tr>\n","    <tr>\n","      <td>18000</td>\n","      <td>1.821500</td>\n","    </tr>\n","    <tr>\n","      <td>19000</td>\n","      <td>1.785000</td>\n","    </tr>\n","    <tr>\n","      <td>20000</td>\n","      <td>1.777700</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Saving model checkpoint to results/checkpoint-500\n","Configuration saved in results/checkpoint-500/config.json\n","Model weights saved in results/checkpoint-500/pytorch_model.bin\n","tokenizer config file saved in results/checkpoint-500/tokenizer_config.json\n","Special tokens file saved in results/checkpoint-500/special_tokens_map.json\n","Saving model checkpoint to results/checkpoint-1000\n","Configuration saved in results/checkpoint-1000/config.json\n","Model weights saved in results/checkpoint-1000/pytorch_model.bin\n","tokenizer config file saved in results/checkpoint-1000/tokenizer_config.json\n","Special tokens file saved in results/checkpoint-1000/special_tokens_map.json\n","Saving model checkpoint to results/checkpoint-1500\n","Configuration saved in results/checkpoint-1500/config.json\n","Model weights saved in results/checkpoint-1500/pytorch_model.bin\n","tokenizer config file saved in results/checkpoint-1500/tokenizer_config.json\n","Special tokens file saved in results/checkpoint-1500/special_tokens_map.json\n","Saving model checkpoint to results/checkpoint-2000\n","Configuration saved in results/checkpoint-2000/config.json\n","Model weights saved in results/checkpoint-2000/pytorch_model.bin\n","tokenizer config file saved in results/checkpoint-2000/tokenizer_config.json\n","Special tokens file saved in results/checkpoint-2000/special_tokens_map.json\n","Deleting older checkpoint [results/checkpoint-500] due to args.save_total_limit\n","Saving model checkpoint to results/checkpoint-2500\n","Configuration saved in results/checkpoint-2500/config.json\n","Model weights saved in results/checkpoint-2500/pytorch_model.bin\n","tokenizer config file saved in results/checkpoint-2500/tokenizer_config.json\n","Special tokens file saved in results/checkpoint-2500/special_tokens_map.json\n","Deleting older checkpoint [results/checkpoint-1000] due to args.save_total_limit\n","Saving model checkpoint to results/checkpoint-3000\n","Configuration saved in results/checkpoint-3000/config.json\n","Model weights saved in results/checkpoint-3000/pytorch_model.bin\n","tokenizer config file saved in results/checkpoint-3000/tokenizer_config.json\n","Special tokens file saved in results/checkpoint-3000/special_tokens_map.json\n","Deleting older checkpoint [results/checkpoint-1500] due to args.save_total_limit\n","Saving model checkpoint to results/checkpoint-3500\n","Configuration saved in results/checkpoint-3500/config.json\n","Model weights saved in results/checkpoint-3500/pytorch_model.bin\n","tokenizer config file saved in results/checkpoint-3500/tokenizer_config.json\n","Special tokens file saved in results/checkpoint-3500/special_tokens_map.json\n","Deleting older checkpoint [results/checkpoint-2000] due to args.save_total_limit\n","Saving model checkpoint to results/checkpoint-4000\n","Configuration saved in results/checkpoint-4000/config.json\n","Model weights saved in results/checkpoint-4000/pytorch_model.bin\n","tokenizer config file saved in results/checkpoint-4000/tokenizer_config.json\n","Special tokens file saved in results/checkpoint-4000/special_tokens_map.json\n","Deleting older checkpoint [results/checkpoint-2500] due to args.save_total_limit\n","Saving model checkpoint to results/checkpoint-4500\n","Configuration saved in results/checkpoint-4500/config.json\n","Model weights saved in results/checkpoint-4500/pytorch_model.bin\n","tokenizer config file saved in results/checkpoint-4500/tokenizer_config.json\n","Special tokens file saved in results/checkpoint-4500/special_tokens_map.json\n","Deleting older checkpoint [results/checkpoint-3000] due to args.save_total_limit\n","Saving model checkpoint to results/checkpoint-5000\n","Configuration saved in results/checkpoint-5000/config.json\n","Model weights saved in results/checkpoint-5000/pytorch_model.bin\n","tokenizer config file saved in results/checkpoint-5000/tokenizer_config.json\n","Special tokens file saved in results/checkpoint-5000/special_tokens_map.json\n","Deleting older checkpoint [results/checkpoint-3500] due to args.save_total_limit\n","Saving model checkpoint to results/checkpoint-5500\n","Configuration saved in results/checkpoint-5500/config.json\n","Model weights saved in results/checkpoint-5500/pytorch_model.bin\n","tokenizer config file saved in results/checkpoint-5500/tokenizer_config.json\n","Special tokens file saved in results/checkpoint-5500/special_tokens_map.json\n","Deleting older checkpoint [results/checkpoint-4000] due to args.save_total_limit\n","Saving model checkpoint to results/checkpoint-6000\n","Configuration saved in results/checkpoint-6000/config.json\n","Model weights saved in results/checkpoint-6000/pytorch_model.bin\n","tokenizer config file saved in results/checkpoint-6000/tokenizer_config.json\n","Special tokens file saved in results/checkpoint-6000/special_tokens_map.json\n","Deleting older checkpoint [results/checkpoint-4500] due to args.save_total_limit\n","Saving model checkpoint to results/checkpoint-6500\n","Configuration saved in results/checkpoint-6500/config.json\n","Model weights saved in results/checkpoint-6500/pytorch_model.bin\n","tokenizer config file saved in results/checkpoint-6500/tokenizer_config.json\n","Special tokens file saved in results/checkpoint-6500/special_tokens_map.json\n","Deleting older checkpoint [results/checkpoint-5000] due to args.save_total_limit\n","Saving model checkpoint to results/checkpoint-7000\n","Configuration saved in results/checkpoint-7000/config.json\n","Model weights saved in results/checkpoint-7000/pytorch_model.bin\n","tokenizer config file saved in results/checkpoint-7000/tokenizer_config.json\n","Special tokens file saved in results/checkpoint-7000/special_tokens_map.json\n","Deleting older checkpoint [results/checkpoint-5500] due to args.save_total_limit\n","Saving model checkpoint to results/checkpoint-7500\n","Configuration saved in results/checkpoint-7500/config.json\n","Model weights saved in results/checkpoint-7500/pytorch_model.bin\n","tokenizer config file saved in results/checkpoint-7500/tokenizer_config.json\n","Special tokens file saved in results/checkpoint-7500/special_tokens_map.json\n","Deleting older checkpoint [results/checkpoint-6000] due to args.save_total_limit\n","Saving model checkpoint to results/checkpoint-8000\n","Configuration saved in results/checkpoint-8000/config.json\n","Model weights saved in results/checkpoint-8000/pytorch_model.bin\n","tokenizer config file saved in results/checkpoint-8000/tokenizer_config.json\n","Special tokens file saved in results/checkpoint-8000/special_tokens_map.json\n","Deleting older checkpoint [results/checkpoint-6500] due to args.save_total_limit\n","Saving model checkpoint to results/checkpoint-8500\n","Configuration saved in results/checkpoint-8500/config.json\n","Model weights saved in results/checkpoint-8500/pytorch_model.bin\n","tokenizer config file saved in results/checkpoint-8500/tokenizer_config.json\n","Special tokens file saved in results/checkpoint-8500/special_tokens_map.json\n","Deleting older checkpoint [results/checkpoint-7000] due to args.save_total_limit\n","Saving model checkpoint to results/checkpoint-9000\n","Configuration saved in results/checkpoint-9000/config.json\n","Model weights saved in results/checkpoint-9000/pytorch_model.bin\n","tokenizer config file saved in results/checkpoint-9000/tokenizer_config.json\n","Special tokens file saved in results/checkpoint-9000/special_tokens_map.json\n","Deleting older checkpoint [results/checkpoint-7500] due to args.save_total_limit\n","Saving model checkpoint to results/checkpoint-9500\n","Configuration saved in results/checkpoint-9500/config.json\n","Model weights saved in results/checkpoint-9500/pytorch_model.bin\n","tokenizer config file saved in results/checkpoint-9500/tokenizer_config.json\n","Special tokens file saved in results/checkpoint-9500/special_tokens_map.json\n","Deleting older checkpoint [results/checkpoint-8000] due to args.save_total_limit\n","Saving model checkpoint to results/checkpoint-10000\n","Configuration saved in results/checkpoint-10000/config.json\n","Model weights saved in results/checkpoint-10000/pytorch_model.bin\n","tokenizer config file saved in results/checkpoint-10000/tokenizer_config.json\n","Special tokens file saved in results/checkpoint-10000/special_tokens_map.json\n","Deleting older checkpoint [results/checkpoint-8500] due to args.save_total_limit\n","Saving model checkpoint to results/checkpoint-10500\n","Configuration saved in results/checkpoint-10500/config.json\n","Model weights saved in results/checkpoint-10500/pytorch_model.bin\n","tokenizer config file saved in results/checkpoint-10500/tokenizer_config.json\n","Special tokens file saved in results/checkpoint-10500/special_tokens_map.json\n","Deleting older checkpoint [results/checkpoint-9000] due to args.save_total_limit\n","Saving model checkpoint to results/checkpoint-11000\n","Configuration saved in results/checkpoint-11000/config.json\n","Model weights saved in results/checkpoint-11000/pytorch_model.bin\n","tokenizer config file saved in results/checkpoint-11000/tokenizer_config.json\n","Special tokens file saved in results/checkpoint-11000/special_tokens_map.json\n","Deleting older checkpoint [results/checkpoint-9500] due to args.save_total_limit\n","Saving model checkpoint to results/checkpoint-11500\n","Configuration saved in results/checkpoint-11500/config.json\n","Model weights saved in results/checkpoint-11500/pytorch_model.bin\n","tokenizer config file saved in results/checkpoint-11500/tokenizer_config.json\n","Special tokens file saved in results/checkpoint-11500/special_tokens_map.json\n","Deleting older checkpoint [results/checkpoint-10000] due to args.save_total_limit\n","Saving model checkpoint to results/checkpoint-12000\n","Configuration saved in results/checkpoint-12000/config.json\n","Model weights saved in results/checkpoint-12000/pytorch_model.bin\n","tokenizer config file saved in results/checkpoint-12000/tokenizer_config.json\n","Special tokens file saved in results/checkpoint-12000/special_tokens_map.json\n","Deleting older checkpoint [results/checkpoint-10500] due to args.save_total_limit\n","Saving model checkpoint to results/checkpoint-12500\n","Configuration saved in results/checkpoint-12500/config.json\n","Model weights saved in results/checkpoint-12500/pytorch_model.bin\n","tokenizer config file saved in results/checkpoint-12500/tokenizer_config.json\n","Special tokens file saved in results/checkpoint-12500/special_tokens_map.json\n","Deleting older checkpoint [results/checkpoint-11000] due to args.save_total_limit\n","Saving model checkpoint to results/checkpoint-13000\n","Configuration saved in results/checkpoint-13000/config.json\n","Model weights saved in results/checkpoint-13000/pytorch_model.bin\n","tokenizer config file saved in results/checkpoint-13000/tokenizer_config.json\n","Special tokens file saved in results/checkpoint-13000/special_tokens_map.json\n","Deleting older checkpoint [results/checkpoint-11500] due to args.save_total_limit\n","Saving model checkpoint to results/checkpoint-13500\n","Configuration saved in results/checkpoint-13500/config.json\n","Model weights saved in results/checkpoint-13500/pytorch_model.bin\n","tokenizer config file saved in results/checkpoint-13500/tokenizer_config.json\n","Special tokens file saved in results/checkpoint-13500/special_tokens_map.json\n","Deleting older checkpoint [results/checkpoint-12000] due to args.save_total_limit\n","Saving model checkpoint to results/checkpoint-14000\n","Configuration saved in results/checkpoint-14000/config.json\n","Model weights saved in results/checkpoint-14000/pytorch_model.bin\n","tokenizer config file saved in results/checkpoint-14000/tokenizer_config.json\n","Special tokens file saved in results/checkpoint-14000/special_tokens_map.json\n","Deleting older checkpoint [results/checkpoint-12500] due to args.save_total_limit\n","Saving model checkpoint to results/checkpoint-14500\n","Configuration saved in results/checkpoint-14500/config.json\n","Model weights saved in results/checkpoint-14500/pytorch_model.bin\n","tokenizer config file saved in results/checkpoint-14500/tokenizer_config.json\n","Special tokens file saved in results/checkpoint-14500/special_tokens_map.json\n","Deleting older checkpoint [results/checkpoint-13000] due to args.save_total_limit\n","Saving model checkpoint to results/checkpoint-15000\n","Configuration saved in results/checkpoint-15000/config.json\n","Model weights saved in results/checkpoint-15000/pytorch_model.bin\n","tokenizer config file saved in results/checkpoint-15000/tokenizer_config.json\n","Special tokens file saved in results/checkpoint-15000/special_tokens_map.json\n","Deleting older checkpoint [results/checkpoint-13500] due to args.save_total_limit\n","Saving model checkpoint to results/checkpoint-15500\n","Configuration saved in results/checkpoint-15500/config.json\n","Model weights saved in results/checkpoint-15500/pytorch_model.bin\n","tokenizer config file saved in results/checkpoint-15500/tokenizer_config.json\n","Special tokens file saved in results/checkpoint-15500/special_tokens_map.json\n","Deleting older checkpoint [results/checkpoint-14000] due to args.save_total_limit\n","Saving model checkpoint to results/checkpoint-16000\n","Configuration saved in results/checkpoint-16000/config.json\n","Model weights saved in results/checkpoint-16000/pytorch_model.bin\n","tokenizer config file saved in results/checkpoint-16000/tokenizer_config.json\n","Special tokens file saved in results/checkpoint-16000/special_tokens_map.json\n","Deleting older checkpoint [results/checkpoint-14500] due to args.save_total_limit\n","Saving model checkpoint to results/checkpoint-16500\n","Configuration saved in results/checkpoint-16500/config.json\n","Model weights saved in results/checkpoint-16500/pytorch_model.bin\n","tokenizer config file saved in results/checkpoint-16500/tokenizer_config.json\n","Special tokens file saved in results/checkpoint-16500/special_tokens_map.json\n","Deleting older checkpoint [results/checkpoint-15000] due to args.save_total_limit\n","Saving model checkpoint to results/checkpoint-17000\n","Configuration saved in results/checkpoint-17000/config.json\n","Model weights saved in results/checkpoint-17000/pytorch_model.bin\n","tokenizer config file saved in results/checkpoint-17000/tokenizer_config.json\n","Special tokens file saved in results/checkpoint-17000/special_tokens_map.json\n","Deleting older checkpoint [results/checkpoint-15500] due to args.save_total_limit\n","Saving model checkpoint to results/checkpoint-17500\n","Configuration saved in results/checkpoint-17500/config.json\n","Model weights saved in results/checkpoint-17500/pytorch_model.bin\n","tokenizer config file saved in results/checkpoint-17500/tokenizer_config.json\n","Special tokens file saved in results/checkpoint-17500/special_tokens_map.json\n","Deleting older checkpoint [results/checkpoint-16000] due to args.save_total_limit\n","Saving model checkpoint to results/checkpoint-18000\n","Configuration saved in results/checkpoint-18000/config.json\n","Model weights saved in results/checkpoint-18000/pytorch_model.bin\n","tokenizer config file saved in results/checkpoint-18000/tokenizer_config.json\n","Special tokens file saved in results/checkpoint-18000/special_tokens_map.json\n","Deleting older checkpoint [results/checkpoint-16500] due to args.save_total_limit\n","Saving model checkpoint to results/checkpoint-18500\n","Configuration saved in results/checkpoint-18500/config.json\n","Model weights saved in results/checkpoint-18500/pytorch_model.bin\n","tokenizer config file saved in results/checkpoint-18500/tokenizer_config.json\n","Special tokens file saved in results/checkpoint-18500/special_tokens_map.json\n","Deleting older checkpoint [results/checkpoint-17000] due to args.save_total_limit\n","Saving model checkpoint to results/checkpoint-19000\n","Configuration saved in results/checkpoint-19000/config.json\n","Model weights saved in results/checkpoint-19000/pytorch_model.bin\n","tokenizer config file saved in results/checkpoint-19000/tokenizer_config.json\n","Special tokens file saved in results/checkpoint-19000/special_tokens_map.json\n","Deleting older checkpoint [results/checkpoint-17500] due to args.save_total_limit\n","Saving model checkpoint to results/checkpoint-19500\n","Configuration saved in results/checkpoint-19500/config.json\n","Model weights saved in results/checkpoint-19500/pytorch_model.bin\n","tokenizer config file saved in results/checkpoint-19500/tokenizer_config.json\n","Special tokens file saved in results/checkpoint-19500/special_tokens_map.json\n","Deleting older checkpoint [results/checkpoint-18000] due to args.save_total_limit\n","Saving model checkpoint to results/checkpoint-20000\n","Configuration saved in results/checkpoint-20000/config.json\n","Model weights saved in results/checkpoint-20000/pytorch_model.bin\n","tokenizer config file saved in results/checkpoint-20000/tokenizer_config.json\n","Special tokens file saved in results/checkpoint-20000/special_tokens_map.json\n","Deleting older checkpoint [results/checkpoint-18500] due to args.save_total_limit\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n"]},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=20000, training_loss=2.5636755920410157, metrics={'train_runtime': 13681.0243, 'train_samples_per_second': 2.924, 'train_steps_per_second': 1.462, 'total_flos': 2.889464414208e+16, 'train_loss': 2.5636755920410157, 'epoch': 8.0})"]},"metadata":{},"execution_count":17}]},{"cell_type":"markdown","metadata":{"id":"V3C-4SfOPssY"},"source":["Evaluate after fine-tuning"]},{"cell_type":"code","metadata":{"id":"_-QyUtCRH9DO","colab":{"base_uri":"https://localhost:8080/","height":263},"outputId":"65f3713a-efab-494a-8393-5ca8597574a2","executionInfo":{"status":"ok","timestamp":1649794982393,"user_tz":300,"elapsed":2939802,"user":{"displayName":"Jose Talavera","userId":"03337362936427322220"}}},"source":["trainer.evaluate()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["***** Running Evaluation *****\n","  Num examples = 500\n","  Batch size = 2\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='500' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [250/250 5:51:22]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["{'epoch': 8.0,\n"," 'eval_gen_len': 351.128,\n"," 'eval_loss': 4.5785040855407715,\n"," 'eval_rouge1': 16.8817,\n"," 'eval_rouge2': 4.5955,\n"," 'eval_rougeL': 11.0601,\n"," 'eval_rougeLsum': 14.5945,\n"," 'eval_runtime': 2939.6179,\n"," 'eval_samples_per_second': 0.17,\n"," 'eval_steps_per_second': 0.085}"]},"metadata":{},"execution_count":18}]},{"cell_type":"code","metadata":{"id":"ClRTrG2ETUm3","colab":{"base_uri":"https://localhost:8080/","height":586,"referenced_widgets":["592ffcb578214a49ae2c30e8cd7639bd","a041807bec27471eaf486e3880553dce","f2800ba3df5c4412aadfae94306c7247","f2db0f1bd83948848a4ca862741dbbce","4e866bff80ea42c8ae2c11ef32c1d539","12f0870792ca44adb0c964d1187aaea5","b275ac404fb0446893e2da778c5f65f4","f4938ad8354d4738b3bad96e14086671"]},"executionInfo":{"status":"ok","timestamp":1649794991658,"user_tz":300,"elapsed":9275,"user":{"displayName":"Jose Talavera","userId":"03337362936427322220"}},"outputId":"31755bb4-25fc-4dad-9ba8-1ef017cd6fa7"},"source":["if WANDB_INTEGRATION:\n","    wandb_run.finish()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"592ffcb578214a49ae2c30e8cd7639bd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/gen_len</td><td>█▁</td></tr><tr><td>eval/loss</td><td>█▁</td></tr><tr><td>eval/rouge1</td><td>▁█</td></tr><tr><td>eval/rouge2</td><td>▁█</td></tr><tr><td>eval/rougeL</td><td>▁█</td></tr><tr><td>eval/rougeLsum</td><td>▁█</td></tr><tr><td>eval/runtime</td><td>█▁</td></tr><tr><td>eval/samples_per_second</td><td>▁█</td></tr><tr><td>eval/steps_per_second</td><td>▁█</td></tr><tr><td>train/epoch</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▂▂▂▃▃▃▄▄▅▅▅▆▆▆▇▇▇████</td></tr><tr><td>train/learning_rate</td><td>██▇▇▇▆▆▅▅▅▄▄▄▃▃▂▂▂▁▁</td></tr><tr><td>train/loss</td><td>█▇▆▅▅▄▄▃▃▃▂▂▂▂▂▁▁▁▁▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/gen_len</td><td>351.128</td></tr><tr><td>eval/loss</td><td>4.5785</td></tr><tr><td>eval/rouge1</td><td>16.8817</td></tr><tr><td>eval/rouge2</td><td>4.5955</td></tr><tr><td>eval/rougeL</td><td>11.0601</td></tr><tr><td>eval/rougeLsum</td><td>14.5945</td></tr><tr><td>eval/runtime</td><td>2939.6179</td></tr><tr><td>eval/samples_per_second</td><td>0.17</td></tr><tr><td>eval/steps_per_second</td><td>0.085</td></tr><tr><td>train/epoch</td><td>8.0</td></tr><tr><td>train/global_step</td><td>20000</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>1.7777</td></tr><tr><td>train/total_flos</td><td>2.889464414208e+16</td></tr><tr><td>train/train_loss</td><td>2.56368</td></tr><tr><td>train/train_runtime</td><td>13681.0243</td></tr><tr><td>train/train_samples_per_second</td><td>2.924</td></tr><tr><td>train/train_steps_per_second</td><td>1.462</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Synced <strong style=\"color:#cdcd00\">crimson-planet-6</strong>: <a href=\"https://wandb.ai/bigbam/distill-Googlepegasus_govreport_FT/runs/d3eqwv74\" target=\"_blank\">https://wandb.ai/bigbam/distill-Googlepegasus_govreport_FT/runs/d3eqwv74</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20220412_143108-d3eqwv74/logs</code>"]},"metadata":{}}]},{"cell_type":"code","source":["!nvidia-smi"],"metadata":{"id":"xpfby90xSSiY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1649794991658,"user_tz":300,"elapsed":12,"user":{"displayName":"Jose Talavera","userId":"03337362936427322220"}},"outputId":"9a61c785-544c-4378-8001-5b0a122ee115"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Tue Apr 12 20:23:12 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   70C    P0    31W /  70W |  14870MiB / 15109MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"markdown","metadata":{"id":"-gSLVnGL9bol"},"source":["## Evaluation\n","\n","---"]},{"cell_type":"markdown","metadata":{"id":"hDwj24cfILS6"},"source":["**Generate summaries from the fine-tuned model and compare them with those generated from the original, pre-trained one.**"]},{"cell_type":"code","metadata":{"id":"NV64-XdA_rOM","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"error","timestamp":1649795612129,"user_tz":300,"elapsed":22176,"user":{"displayName":"Jose Talavera","userId":"03337362936427322220"}},"outputId":"383c6a23-c8bd-4928-819b-034d8b058918"},"source":["def generate_summary(test_samples, model):\n","    inputs = tokenizer(\n","        test_samples[\"report\"],\n","        padding=\"max_length\",\n","        truncation=True,\n","        max_length=encoder_max_length,\n","        return_tensors=\"pt\",\n","    )\n","    input_ids = inputs.input_ids.to(model.device)\n","    attention_mask = inputs.attention_mask.to(model.device)\n","    outputs = model.generate(input_ids, attention_mask=attention_mask)\n","    output_str = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n","    return outputs, output_str\n","\n","\n","model_before_tuning = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n","\n","test_samples = validation_data_txt.select(range(16))\n","\n","summaries_before_tuning = generate_summary(test_samples, model_before_tuning)[1]\n","summaries_after_tuning = generate_summary(test_samples, model)[1]"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["loading configuration file https://huggingface.co/google/pegasus-billsum/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/9bd6942fd69c3d18680196bab46e04a9666e530dfff5bdfbefedf6557c56e481.d231824558a1b622d0c4eda41887f8b3d5f176f8f2f992d9940ab3123cb8665f\n","Model config PegasusConfig {\n","  \"_name_or_path\": \"google/pegasus-billsum\",\n","  \"activation_dropout\": 0.1,\n","  \"activation_function\": \"relu\",\n","  \"add_bias_logits\": false,\n","  \"add_final_layer_norm\": true,\n","  \"architectures\": [\n","    \"PegasusForConditionalGeneration\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classif_dropout\": 0.0,\n","  \"classifier_dropout\": 0.0,\n","  \"d_model\": 1024,\n","  \"decoder_attention_heads\": 16,\n","  \"decoder_ffn_dim\": 4096,\n","  \"decoder_layerdrop\": 0.0,\n","  \"decoder_layers\": 16,\n","  \"decoder_start_token_id\": 0,\n","  \"dropout\": 0.1,\n","  \"encoder_attention_heads\": 16,\n","  \"encoder_ffn_dim\": 4096,\n","  \"encoder_layerdrop\": 0.0,\n","  \"encoder_layers\": 16,\n","  \"eos_token_id\": 1,\n","  \"extra_pos_embeddings\": 1,\n","  \"forced_eos_token_id\": 1,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"length_penalty\": 0.6,\n","  \"max_length\": 256,\n","  \"max_position_embeddings\": 1024,\n","  \"min_length\": 32,\n","  \"model_type\": \"pegasus\",\n","  \"normalize_before\": true,\n","  \"normalize_embedding\": false,\n","  \"num_beams\": 8,\n","  \"num_hidden_layers\": 16,\n","  \"pad_token_id\": 0,\n","  \"scale_embedding\": true,\n","  \"static_position_embeddings\": true,\n","  \"transformers_version\": \"4.18.0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 96103\n","}\n","\n","loading weights file https://huggingface.co/google/pegasus-billsum/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/0278830453da853a6f44703bf328e1c4b4b7762a15a262ceca83e9a6aaa3c6f3.3e29abd2379a24e4465f850ced3e894ba06ed8d4e7ace19d15a8b227f5767228\n","All model checkpoint weights were used when initializing PegasusForConditionalGeneration.\n","\n","All the weights of PegasusForConditionalGeneration were initialized from the model checkpoint at google/pegasus-billsum.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use PegasusForConditionalGeneration for predictions without further training.\n"]},{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-22-6246eb002a64>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0msummaries_after_tuning\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-22-6246eb002a64>\u001b[0m in \u001b[0;36mgenerate_summary\u001b[0;34m(test_samples, model)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0minput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mattention_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0moutput_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_str\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/generation_utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, max_length, min_length, do_sample, early_stopping, num_beams, temperature, top_k, top_p, typical_p, repetition_penalty, bad_words_ids, force_words_ids, bos_token_id, pad_token_id, eos_token_id, length_penalty, no_repeat_ngram_size, encoder_no_repeat_ngram_size, num_return_sequences, max_time, max_new_tokens, decoder_start_token_id, use_cache, num_beam_groups, diversity_penalty, prefix_allowed_tokens_fn, logits_processor, stopping_criteria, constraints, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, forced_bos_token_id, forced_eos_token_id, remove_invalid_values, synced_gpus, exponential_decay_length_penalty, **model_kwargs)\u001b[0m\n\u001b[1;32m   1155\u001b[0m             \u001b[0;31m# and added to `model_kwargs`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1156\u001b[0m             model_kwargs = self._prepare_encoder_decoder_kwargs_for_generation(\n\u001b[0;32m-> 1157\u001b[0;31m                 \u001b[0minputs_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_input_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1158\u001b[0m             )\n\u001b[1;32m   1159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/generation_utils.py\u001b[0m in \u001b[0;36m_prepare_encoder_decoder_kwargs_for_generation\u001b[0;34m(self, inputs_tensor, model_kwargs, model_input_name)\u001b[0m\n\u001b[1;32m    522\u001b[0m         \u001b[0mencoder_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"return_dict\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m         \u001b[0mencoder_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_input_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs_tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 524\u001b[0;31m         \u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"encoder_outputs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mModelOutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mencoder_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    525\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    526\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/pegasus/modeling_pegasus.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    804\u001b[0m                         \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    805\u001b[0m                         \u001b[0mlayer_head_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhead_mask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 806\u001b[0;31m                         \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    807\u001b[0m                     )\n\u001b[1;32m    808\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/pegasus/modeling_pegasus.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, layer_head_mask, output_attentions)\u001b[0m\n\u001b[1;32m    328\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m             \u001b[0mlayer_head_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlayer_head_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 330\u001b[0;31m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    331\u001b[0m         )\n\u001b[1;32m    332\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/pegasus/modeling_pegasus.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, key_value_states, past_key_value, attention_mask, layer_head_mask, output_attentions)\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0;31m# get query proj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mquery_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mq_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m         \u001b[0;31m# get key, value proj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_cross_attention\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mpast_key_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.76 GiB total capacity; 13.16 GiB already allocated; 15.75 MiB free; 13.28 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"]}]},{"cell_type":"code","metadata":{"id":"D7IPtJLjCcmS"},"source":["print(\n","    tabulate(\n","        zip(\n","            range(len(summaries_after_tuning)),\n","            summaries_after_tuning,\n","            summaries_before_tuning,\n","        ),\n","        headers=[\"Id\", \"Summary after\", \"Summary before\"],\n","    )\n",")\n","print(\"\\nTarget summaries:\\n\")\n","print(\n","    tabulate(list(enumerate(test_samples[\"report\"])), headers=[\"Id\", \"Target summary\"])\n",")\n","print(\"\\nSource documents:\\n\")\n","print(tabulate(list(enumerate(test_samples[\"summary\"])), headers=[\"Id\", \"Document\"]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dLiP9Q5QWg-A"},"source":[""],"execution_count":null,"outputs":[]}]}