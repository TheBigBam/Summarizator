{"cells":[{"cell_type":"markdown","metadata":{"id":"X8VR8kd4ipPN"},"source":["\n","# Fine-tuning Pegasus Summarization\n","\n","---"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1650603904931,"user":{"displayName":"Jose Talavera","userId":"03337362936427322220"},"user_tz":300},"id":"zImELPsbXADJ","outputId":"bc264dff-1eac-431e-f6eb-0a49b985b045"},"outputs":[{"output_type":"stream","name":"stdout","text":["Fri Apr 22 05:05:04 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   39C    P0    28W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi"]},{"cell_type":"markdown","metadata":{"id":"yUn2OqI9oPQb"},"source":["## Setup\n","\n","---"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3960,"status":"ok","timestamp":1650603908885,"user":{"displayName":"Jose Talavera","userId":"03337362936427322220"},"user_tz":300},"id":"pkzypz9I1O6H","outputId":"dad69b04-d786-4fa4-f0ab-2532a8badda6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: ipywidgets in /usr/local/lib/python3.7/dist-packages (7.7.0)\n","Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.7/dist-packages (from ipywidgets) (5.1.1)\n","Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets) (1.1.0)\n","Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets) (5.5.0)\n","Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets) (3.6.0)\n","Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets) (0.2.0)\n","Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets) (5.3.0)\n","Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.7/dist-packages (from ipywidgets) (4.10.1)\n","Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel>=4.5.1->ipywidgets) (5.1.1)\n","Requirement already satisfied: jupyter-client in /usr/local/lib/python3.7/dist-packages (from ipykernel>=4.5.1->ipywidgets) (5.3.5)\n","Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets) (1.0.18)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets) (2.6.1)\n","Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets) (0.8.1)\n","Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets) (4.8.0)\n","Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets) (57.4.0)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets) (0.7.5)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets) (4.4.2)\n","Requirement already satisfied: jupyter-core in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets) (4.9.2)\n","Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets) (4.3.3)\n","Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets) (2.15.3)\n","Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat>=4.2.0->ipywidgets) (5.7.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat>=4.2.0->ipywidgets) (4.1.1)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat>=4.2.0->ipywidgets) (4.11.3)\n","Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat>=4.2.0->ipywidgets) (21.4.0)\n","Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat>=4.2.0->ipywidgets) (0.18.1)\n","Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources>=1.4.0->jsonschema>=2.6->nbformat>=4.2.0->ipywidgets) (3.8.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0->ipywidgets) (0.2.5)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0->ipywidgets) (1.15.0)\n","Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.7/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets) (5.3.1)\n","Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.13.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.11.3)\n","Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (5.6.1)\n","Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.8.0)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets) (2.8.2)\n","Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets) (22.3.0)\n","Requirement already satisfied: ptyprocess in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.1->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.7.0)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.0.1)\n","Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.5.0)\n","Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.8.4)\n","Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (5.0.0)\n","Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.6.0)\n","Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.4)\n","Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.7.1)\n","Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.5.1)\n","Enabling notebook extension jupyter-js-widgets/extension...\n","Paths used for configuration of notebook: \n","    \t/root/.jupyter/nbconfig/notebook.json\n","      - Validating: \u001b[32mOK\u001b[0m\n","Paths used for configuration of notebook: \n","    \t/root/.jupyter/nbconfig/notebook.json\n"]}],"source":["!pip install ipywidgets\n","!jupyter nbextension enable --py widgetsnbextension"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14809,"status":"ok","timestamp":1650603923690,"user":{"displayName":"Jose Talavera","userId":"03337362936427322220"},"user_tz":300},"id":"_gaaojSBoQ5f","outputId":"f864552a-e95e-42ef-8b20-0809b93ca294"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.18.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.5.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.49)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.8)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.25.11)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n","Requirement already satisfied: datasets in /usr/local/lib/python3.7/dist-packages (2.1.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.21.6)\n","Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.4)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.12.2)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets) (3.0.0)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.11.3)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets) (3.8.1)\n","Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.18.0)\n","Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.5.1)\n","Requirement already satisfied: pyarrow>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.64.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\n","Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2022.3.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (4.1.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.6.0)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.25.11)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2021.10.8)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.7.2)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (6.0.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (21.4.0)\n","Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.0.12)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.2.0)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.0.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.3.0)\n","Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (0.13.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.8.0)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2022.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.96)\n","Requirement already satisfied: rouge_score in /usr/local/lib/python3.7/dist-packages (0.0.4)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from rouge_score) (1.21.6)\n","Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from rouge_score) (1.15.0)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from rouge_score) (3.2.5)\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from rouge_score) (1.0.0)\n","Requirement already satisfied: wandb in /usr/local/lib/python3.7/dist-packages (0.12.15)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (6.0)\n","Requirement already satisfied: GitPython>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.1.27)\n","Requirement already satisfied: shortuuid>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.0.8)\n","Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n","Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.17.3)\n","Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.5.10)\n","Requirement already satisfied: setproctitle in /usr/local/lib/python3.7/dist-packages (from wandb) (1.2.3)\n","Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n","Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (0.4.0)\n","Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.8.2)\n","Requirement already satisfied: pathtools in /usr/local/lib/python3.7/dist-packages (from wandb) (0.1.2)\n","Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n","Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n","Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (4.0.9)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (4.1.1)\n","Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (5.0.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2021.10.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (1.25.11)\n"]}],"source":["! pip install transformers\n","! pip install datasets\n","! pip install sentencepiece\n","! pip install rouge_score\n","! pip install wandb"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":9045,"status":"ok","timestamp":1650603932720,"user":{"displayName":"Jose Talavera","userId":"03337362936427322220"},"user_tz":300},"id":"rimUDCQGoTAJ"},"outputs":[],"source":["import torch\n","import numpy as np\n","import datasets\n","\n","from transformers import (\n","    AutoModelForSeq2SeqLM,\n","    AutoTokenizer,\n","    Seq2SeqTrainingArguments,\n","    Seq2SeqTrainer,\n","    DataCollatorForSeq2Seq,\n",")\n","\n","from tabulate import tabulate\n","import nltk\n","from datetime import datetime"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1731,"status":"ok","timestamp":1650603934431,"user":{"displayName":"Jose Talavera","userId":"03337362936427322220"},"user_tz":300},"id":"8zpflBQbzrvC","outputId":"e77648d7-ca3a-4de1-b1c4-02fe226b806e"},"outputs":[{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbigbam\u001b[0m (use `wandb login --relogin` to force relogin)\n"]}],"source":["WANDB_INTEGRATION = True\n","if WANDB_INTEGRATION:\n","    import wandb\n","\n","    wandb.login()"]},{"cell_type":"markdown","metadata":{"id":"aX-q_O-hoe3g"},"source":["## Model and tokenizer\n","\n","---"]},{"cell_type":"markdown","metadata":{"id":"yb21WY-9mavn"},"source":["Hiperparámetros: \n","\n","[HF Bart configuration](https://huggingface.co/transformers/_modules/transformers/configuration_bart.html)\n","\n","[Fairseq Bart](https://github.com/pytorch/fairseq/tree/master/examples/bart)"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"VtEDrBTfwcEC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650603934464,"user_tz":300,"elapsed":62,"user":{"displayName":"Jose Talavera","userId":"03337362936427322220"}},"outputId":"f050f7ac-40ee-4d6a-b615-206f5fc61207"},"outputs":[{"output_type":"stream","name":"stdout","text":["True\n"]}],"source":["import tensorflow as tf\n","print(tf.test.is_built_with_cuda())"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10928,"status":"ok","timestamp":1650603945342,"user":{"displayName":"Jose Talavera","userId":"03337362936427322220"},"user_tz":300},"id":"7vMhyyIPobyx","outputId":"898eeb33-6fab-4395-9f66-4065a385c84d"},"outputs":[{"output_type":"stream","name":"stdout","text":["PegasusConfig {\n","  \"_name_or_path\": \"google/pegasus-xsum\",\n","  \"activation_dropout\": 0.0,\n","  \"activation_function\": \"relu\",\n","  \"add_bias_logits\": false,\n","  \"add_final_layer_norm\": true,\n","  \"architectures\": [\n","    \"PegasusForConditionalGeneration\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classif_dropout\": 0.0,\n","  \"classifier_dropout\": 0.0,\n","  \"d_model\": 1024,\n","  \"decoder_attention_heads\": 16,\n","  \"decoder_ffn_dim\": 4096,\n","  \"decoder_layerdrop\": 0.0,\n","  \"decoder_layers\": 16,\n","  \"decoder_start_token_id\": 0,\n","  \"do_blenderbot_90_layernorm\": false,\n","  \"dropout\": 0.1,\n","  \"encoder_attention_heads\": 16,\n","  \"encoder_ffn_dim\": 4096,\n","  \"encoder_layerdrop\": 0.0,\n","  \"encoder_layers\": 16,\n","  \"eos_token_id\": 1,\n","  \"extra_pos_embeddings\": 0,\n","  \"force_bos_token_to_be_generated\": false,\n","  \"forced_eos_token_id\": 1,\n","  \"gradient_checkpointing\": false,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"length_penalty\": 0.6,\n","  \"max_length\": 2000,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"pegasus\",\n","  \"normalize_before\": true,\n","  \"normalize_embedding\": false,\n","  \"num_beams\": 8,\n","  \"num_hidden_layers\": 16,\n","  \"pad_token_id\": 0,\n","  \"scale_embedding\": true,\n","  \"static_position_embeddings\": true,\n","  \"transformers_version\": \"4.18.0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 96103\n","}\n","\n"]}],"source":["#Llamado del modelo\n","# model_name = \"sshleifer/distill-pegasus-xsum-16-8\"\n","model_name = \"google/pegasus-xsum\"\n","#Definición de modelo y tokenizador\n","model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","\n","# Se fijan los parámetros del modelo\n","model.config.activation_dropout = 0.0\n","model.config.max_length=2000\n","print(model.config)\n","\n","# tokenización\n","encoder_max_length = 256 \n","decoder_max_length = 64"]},{"cell_type":"markdown","metadata":{"id":"wwtSPRJgomBS"},"source":["## Data\n","\n","---"]},{"cell_type":"markdown","metadata":{"id":"OZfrIK8fW9DU"},"source":["### Descarga y Preparación de los Datos"]},{"cell_type":"markdown","metadata":{"id":"t4MZ_LiNwI_T"},"source":["### Cargado de Dataset"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"N0TPG-bEk-uU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650603946095,"user_tz":300,"elapsed":771,"user":{"displayName":"Jose Talavera","userId":"03337362936427322220"}},"outputId":"ac8ac23b-1f79-4663-8ef1-c52a6304e1e8"},"outputs":[{"output_type":"stream","name":"stderr","text":["Using custom data configuration 3.0.0\n","Reusing dataset billsum (/root/.cache/huggingface/datasets/billsum/3.0.0/3.0.0/d1e95173aed3acb71327864be74ead49b578522e4c7206048b2f2e5351b57959)\n","Using custom data configuration 3.0.0\n","Reusing dataset billsum (/root/.cache/huggingface/datasets/billsum/3.0.0/3.0.0/d1e95173aed3acb71327864be74ead49b578522e4c7206048b2f2e5351b57959)\n"]}],"source":["train_data_txt = datasets.load_dataset(\"billsum\", '3.0.0', split=\"train\")\n","validation_data_txt = datasets.load_dataset(\"billsum\", '3.0.0', split=\"test[:100]\")"]},{"cell_type":"markdown","metadata":{"id":"5pbe750YpMfD"},"source":["**Preprocess and tokenize**"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":86,"referenced_widgets":["82f331884b5140a19b3fa2cac92f850c","badb6456430a419e98d4d6a9a012b172","9604c9a5d9d14f9ebdf1906bcd6d5fe2","033a2ef8b4ba4154abc9520edf516dfe","1de9f76982d9425e92d659b5ee1ec1cd","9805721a4250478faa315e3e235e9cbb","3d12bf7360004e0d8380ddb75019b58b","d1dcc1fc510447b487a4c6c0c3bb430e","1114696de2cb475f842ef761483f652a","5c5e5287edf44a55a1af8a7170bdf00c","fd77d25c86d943a6990c5d49166ee95e"]},"id":"PyksYNwxA4OM","executionInfo":{"status":"ok","timestamp":1650603946511,"user_tz":300,"elapsed":436,"user":{"displayName":"Jose Talavera","userId":"03337362936427322220"}},"outputId":"e1cbcb5c-6174-410a-9051-a3c0af9568f2"},"outputs":[{"output_type":"stream","name":"stderr","text":["Loading cached processed dataset at /root/.cache/huggingface/datasets/billsum/3.0.0/3.0.0/d1e95173aed3acb71327864be74ead49b578522e4c7206048b2f2e5351b57959/cache-1ddeebe9341c1f68.arrow\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/1 [00:00<?, ?ba/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"82f331884b5140a19b3fa2cac92f850c"}},"metadata":{}}],"source":["def batch_tokenize_preprocess(batch, tokenizer, max_source_length, max_target_length):\n","    source, target = batch[\"text\"], batch[\"summary\"]\n","    source_tokenized = tokenizer(\n","        source, padding=\"max_length\", truncation=True, max_length=max_source_length\n","    )\n","    target_tokenized = tokenizer(\n","        target, padding=\"max_length\", truncation=True, max_length=max_target_length\n","    )\n","\n","    batch = {k: v for k, v in source_tokenized.items()}\n","    # Ignore padding in the loss\n","    batch[\"labels\"] = [\n","        [-100 if token == tokenizer.pad_token_id else token for token in l]\n","        for l in target_tokenized[\"input_ids\"]\n","    ]\n","    return batch\n","\n","\n","train_data = train_data_txt.map(\n","    lambda batch: batch_tokenize_preprocess(\n","        batch, tokenizer, encoder_max_length, decoder_max_length\n","    ),\n","    batched=True,\n","    remove_columns=train_data_txt.column_names,\n",")\n","\n","validation_data = validation_data_txt.map(\n","    lambda batch: batch_tokenize_preprocess(\n","        batch, tokenizer, encoder_max_length, decoder_max_length\n","    ),\n","    batched=True,\n","    remove_columns=validation_data_txt.column_names,\n",")"]},{"cell_type":"markdown","metadata":{"id":"h7ViBmMopWfb"},"source":["## Training\n","\n","---"]},{"cell_type":"markdown","metadata":{"id":"9EfTztMPv2vG"},"source":["### Metrics"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"rpNCGl2sYl2p","executionInfo":{"status":"ok","timestamp":1650603946908,"user_tz":300,"elapsed":401,"user":{"displayName":"Jose Talavera","userId":"03337362936427322220"}}},"outputs":[],"source":["# Borrowed from https://github.com/huggingface/transformers/blob/master/examples/seq2seq/run_summarization.py\n","\n","nltk.download(\"punkt\", quiet=True)\n","\n","metric = datasets.load_metric(\"rouge\")\n","\n","\n","def postprocess_text(preds, labels):\n","    preds = [pred.strip() for pred in preds]\n","    labels = [label.strip() for label in labels]\n","\n","    # rougeLSum expects newline after each sentence\n","    preds = [\"\\n\".join(nltk.sent_tokenize(pred)) for pred in preds]\n","    labels = [\"\\n\".join(nltk.sent_tokenize(label)) for label in labels]\n","\n","    return preds, labels\n","\n","\n","def compute_metrics(eval_preds):\n","    preds, labels = eval_preds\n","    if isinstance(preds, tuple):\n","        preds = preds[0]\n","    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n","    # Replace -100 in the labels as we can't decode them.\n","    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n","    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n","\n","    # Some simple post-processing\n","    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n","\n","    result = metric.compute(\n","        predictions=decoded_preds, references=decoded_labels, use_stemmer=True\n","    )\n","    # Extract a few results from ROUGE\n","    result = {key: value.mid.fmeasure * 100 for key, value in result.items()}\n","\n","    prediction_lens = [\n","        np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds\n","    ]\n","    result[\"gen_len\"] = np.mean(prediction_lens)\n","    result = {k: round(v, 4) for k, v in result.items()}\n","    return result"]},{"cell_type":"markdown","metadata":{"id":"8O1EeUi-pbPA"},"source":["### Training arguments"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"6R9d7ELIpX9F","executionInfo":{"status":"ok","timestamp":1650603952862,"user_tz":300,"elapsed":5960,"user":{"displayName":"Jose Talavera","userId":"03337362936427322220"}}},"outputs":[],"source":["training_args = Seq2SeqTrainingArguments(\n","    output_dir=\"results\",\n","    num_train_epochs=8,  # demo\n","    do_train=True,\n","    do_eval=True,\n","    per_device_train_batch_size=4,  # demo\n","    per_device_eval_batch_size=4,\n","    learning_rate=3e-04,\n","    warmup_steps=5000,\n","    weight_decay=0.1,\n","    label_smoothing_factor=0.1,\n","    predict_with_generate=True, #Para métricas ROUGE\n","    logging_dir=\"logs\",\n","    logging_steps=1000,\n","    save_total_limit=3,\n",")\n","\n","data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n","\n","trainer = Seq2SeqTrainer(\n","    model=model,\n","    args=training_args,\n","    data_collator=data_collator,\n","    train_dataset=train_data,\n","    eval_dataset=validation_data,\n","    tokenizer=tokenizer,\n","    compute_metrics=compute_metrics,\n",")"]},{"cell_type":"markdown","metadata":{"id":"Qzcsz3gKplPO"},"source":["### Train"]},{"cell_type":"markdown","metadata":{"id":"Rpg2a0mfoD-l"},"source":["Wandb integration"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"Ns6c0cMuWDXp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650603952866,"user_tz":300,"elapsed":30,"user":{"displayName":"Jose Talavera","userId":"03337362936427322220"}},"outputId":"9d651729-8de9-415b-b733-2f99a1aabd3d"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<module 'wandb' from '/usr/local/lib/python3.7/dist-packages/wandb/__init__.py'>"]},"metadata":{},"execution_count":12}],"source":["wandb"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"tdaVPp9doF1c","colab":{"base_uri":"https://localhost:8080/","height":69},"executionInfo":{"status":"ok","timestamp":1650603956465,"user_tz":300,"elapsed":3620,"user":{"displayName":"Jose Talavera","userId":"03337362936427322220"}},"outputId":"4535877c-8478-487c-8df5-89d93de1bac9"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.12.15"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20220422_050552-2rihcx5x</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href=\"https://wandb.ai/bigbam/distill-pegasus_billsum_FT/runs/2rihcx5x\" target=\"_blank\">logical-tree-15</a></strong> to <a href=\"https://wandb.ai/bigbam/distill-pegasus_billsum_FT\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"]},"metadata":{}}],"source":["if WANDB_INTEGRATION:\n","    wandb_run = wandb.init(\n","        project=\"distill-pegasus_billsum_FT\",\n","        config={\n","            \"per_device_train_batch_size\": training_args.per_device_train_batch_size,\n","            \"learning_rate\": training_args.learning_rate,\n","            \"dataset\": \"billsum\",\n","        },\n","    )\n","\n","    now = datetime.now()\n","    current_time = now.strftime(\"%H%M%S\")\n","    wandb_run.name = \"run_\" + current_time"]},{"cell_type":"markdown","metadata":{"id":"kEtd_a7TPpkd"},"source":["Evaluate before fine-tuning"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"5yveDiz7pm3i","colab":{"base_uri":"https://localhost:8080/","height":283},"executionInfo":{"status":"ok","timestamp":1650604014479,"user_tz":300,"elapsed":58039,"user":{"displayName":"Jose Talavera","userId":"03337362936427322220"}},"outputId":"244bec19-bdc1-452e-bd5c-2ea1ac8b4da4"},"outputs":[{"output_type":"stream","name":"stderr","text":["***** Running Evaluation *****\n","  Num examples = 100\n","  Batch size = 4\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='25' max='25' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [25/25 00:55]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"]},{"output_type":"execute_result","data":{"text/plain":["{'eval_gen_len': 27.28,\n"," 'eval_loss': 3.938535213470459,\n"," 'eval_rouge1': 29.3814,\n"," 'eval_rouge2': 16.5556,\n"," 'eval_rougeL': 23.6384,\n"," 'eval_rougeLsum': 24.9062,\n"," 'eval_runtime': 57.8577,\n"," 'eval_samples_per_second': 1.728,\n"," 'eval_steps_per_second': 0.432}"]},"metadata":{},"execution_count":14}],"source":["trainer.evaluate()"]},{"cell_type":"markdown","metadata":{"id":"nkRb7hvgPrf2"},"source":["Train the model"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"PZLM53u6mXyF","executionInfo":{"status":"ok","timestamp":1650604014480,"user_tz":300,"elapsed":32,"user":{"displayName":"Jose Talavera","userId":"03337362936427322220"}}},"outputs":[],"source":["torch.cuda.is_available()\n","import tensorflow as tf"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"ZgJsTMNan2cQ","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1650604014481,"user_tz":300,"elapsed":32,"user":{"displayName":"Jose Talavera","userId":"03337362936427322220"}},"outputId":"4eb7c1b9-bbeb-48fa-a2a8-07c31364d5bc"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/device:GPU:0'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":16}],"source":["tf.test.gpu_device_name()"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"qYcYcbkr7ZZD","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1650626226575,"user_tz":300,"elapsed":22212124,"user":{"displayName":"Jose Talavera","userId":"03337362936427322220"}},"outputId":"03836664-a688-4be5-8eb0-b6794040bfae"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","***** Running training *****\n","  Num examples = 18949\n","  Num Epochs = 8\n","  Instantaneous batch size per device = 4\n","  Total train batch size (w. parallel, distributed & accumulation) = 4\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 37904\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='37904' max='37904' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [37904/37904 6:10:11, Epoch 8/8]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1000</td>\n","      <td>3.651500</td>\n","    </tr>\n","    <tr>\n","      <td>2000</td>\n","      <td>3.201500</td>\n","    </tr>\n","    <tr>\n","      <td>3000</td>\n","      <td>3.081600</td>\n","    </tr>\n","    <tr>\n","      <td>4000</td>\n","      <td>2.990400</td>\n","    </tr>\n","    <tr>\n","      <td>5000</td>\n","      <td>2.906000</td>\n","    </tr>\n","    <tr>\n","      <td>6000</td>\n","      <td>2.793200</td>\n","    </tr>\n","    <tr>\n","      <td>7000</td>\n","      <td>2.780000</td>\n","    </tr>\n","    <tr>\n","      <td>8000</td>\n","      <td>2.763300</td>\n","    </tr>\n","    <tr>\n","      <td>9000</td>\n","      <td>2.747200</td>\n","    </tr>\n","    <tr>\n","      <td>10000</td>\n","      <td>2.618200</td>\n","    </tr>\n","    <tr>\n","      <td>11000</td>\n","      <td>2.498600</td>\n","    </tr>\n","    <tr>\n","      <td>12000</td>\n","      <td>2.510300</td>\n","    </tr>\n","    <tr>\n","      <td>13000</td>\n","      <td>2.494400</td>\n","    </tr>\n","    <tr>\n","      <td>14000</td>\n","      <td>2.494300</td>\n","    </tr>\n","    <tr>\n","      <td>15000</td>\n","      <td>2.310200</td>\n","    </tr>\n","    <tr>\n","      <td>16000</td>\n","      <td>2.285500</td>\n","    </tr>\n","    <tr>\n","      <td>17000</td>\n","      <td>2.284600</td>\n","    </tr>\n","    <tr>\n","      <td>18000</td>\n","      <td>2.290100</td>\n","    </tr>\n","    <tr>\n","      <td>19000</td>\n","      <td>2.287600</td>\n","    </tr>\n","    <tr>\n","      <td>20000</td>\n","      <td>2.088600</td>\n","    </tr>\n","    <tr>\n","      <td>21000</td>\n","      <td>2.106000</td>\n","    </tr>\n","    <tr>\n","      <td>22000</td>\n","      <td>2.107800</td>\n","    </tr>\n","    <tr>\n","      <td>23000</td>\n","      <td>2.107400</td>\n","    </tr>\n","    <tr>\n","      <td>24000</td>\n","      <td>2.063100</td>\n","    </tr>\n","    <tr>\n","      <td>25000</td>\n","      <td>1.952100</td>\n","    </tr>\n","    <tr>\n","      <td>26000</td>\n","      <td>1.955400</td>\n","    </tr>\n","    <tr>\n","      <td>27000</td>\n","      <td>1.956700</td>\n","    </tr>\n","    <tr>\n","      <td>28000</td>\n","      <td>1.958900</td>\n","    </tr>\n","    <tr>\n","      <td>29000</td>\n","      <td>1.888700</td>\n","    </tr>\n","    <tr>\n","      <td>30000</td>\n","      <td>1.834500</td>\n","    </tr>\n","    <tr>\n","      <td>31000</td>\n","      <td>1.842800</td>\n","    </tr>\n","    <tr>\n","      <td>32000</td>\n","      <td>1.846100</td>\n","    </tr>\n","    <tr>\n","      <td>33000</td>\n","      <td>1.839400</td>\n","    </tr>\n","    <tr>\n","      <td>34000</td>\n","      <td>1.775900</td>\n","    </tr>\n","    <tr>\n","      <td>35000</td>\n","      <td>1.761600</td>\n","    </tr>\n","    <tr>\n","      <td>36000</td>\n","      <td>1.759200</td>\n","    </tr>\n","    <tr>\n","      <td>37000</td>\n","      <td>1.758800</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Saving model checkpoint to results/checkpoint-500\n","Configuration saved in results/checkpoint-500/config.json\n","Model weights saved in results/checkpoint-500/pytorch_model.bin\n","tokenizer config file saved in results/checkpoint-500/tokenizer_config.json\n","Special tokens file saved in results/checkpoint-500/special_tokens_map.json\n","Deleting older checkpoint [results/checkpoint-74500] due to args.save_total_limit\n","Saving model checkpoint to results/checkpoint-1000\n","Configuration saved in results/checkpoint-1000/config.json\n","Model weights saved in results/checkpoint-1000/pytorch_model.bin\n","tokenizer config file saved in results/checkpoint-1000/tokenizer_config.json\n","Special tokens file saved in results/checkpoint-1000/special_tokens_map.json\n","Deleting older checkpoint [results/checkpoint-75000] due to args.save_total_limit\n","Saving model checkpoint to results/checkpoint-1500\n","Configuration saved in results/checkpoint-1500/config.json\n","Model weights saved in results/checkpoint-1500/pytorch_model.bin\n","tokenizer config file saved in results/checkpoint-1500/tokenizer_config.json\n","Special tokens file saved in results/checkpoint-1500/special_tokens_map.json\n","Deleting older checkpoint [results/checkpoint-75500] due to args.save_total_limit\n","Saving model checkpoint to results/checkpoint-2000\n","Configuration saved in results/checkpoint-2000/config.json\n","Model weights saved in results/checkpoint-2000/pytorch_model.bin\n","tokenizer config file saved in results/checkpoint-2000/tokenizer_config.json\n","Special tokens file saved in results/checkpoint-2000/special_tokens_map.json\n","Deleting older checkpoint [results/checkpoint-500] due to args.save_total_limit\n","Saving model checkpoint to results/checkpoint-2500\n","Configuration saved in results/checkpoint-2500/config.json\n","Model weights saved in results/checkpoint-2500/pytorch_model.bin\n","tokenizer config file saved in results/checkpoint-2500/tokenizer_config.json\n","Special tokens file saved in results/checkpoint-2500/special_tokens_map.json\n","Deleting older checkpoint [results/checkpoint-1000] due to args.save_total_limit\n","Saving model checkpoint to results/checkpoint-3000\n","Configuration saved in results/checkpoint-3000/config.json\n","Model weights saved in results/checkpoint-3000/pytorch_model.bin\n","tokenizer config file saved in results/checkpoint-3000/tokenizer_config.json\n","Special tokens file saved in results/checkpoint-3000/special_tokens_map.json\n","Deleting older checkpoint [results/checkpoint-1500] due to args.save_total_limit\n","Saving model checkpoint to results/checkpoint-3500\n","Configuration saved in results/checkpoint-3500/config.json\n","Model weights saved in results/checkpoint-3500/pytorch_model.bin\n","tokenizer config file saved in results/checkpoint-3500/tokenizer_config.json\n","Special tokens file saved in results/checkpoint-3500/special_tokens_map.json\n","Deleting older checkpoint [results/checkpoint-2000] due to args.save_total_limit\n","Saving model checkpoint to results/checkpoint-4000\n","Configuration saved in results/checkpoint-4000/config.json\n","Model weights saved in results/checkpoint-4000/pytorch_model.bin\n","tokenizer config file saved in results/checkpoint-4000/tokenizer_config.json\n","Special tokens file saved in results/checkpoint-4000/special_tokens_map.json\n","Deleting older checkpoint [results/checkpoint-2500] due to args.save_total_limit\n","Saving model checkpoint to results/checkpoint-4500\n","Configuration saved in results/checkpoint-4500/config.json\n","Model weights saved in results/checkpoint-4500/pytorch_model.bin\n","tokenizer config file saved in results/checkpoint-4500/tokenizer_config.json\n","Special tokens file saved in results/checkpoint-4500/special_tokens_map.json\n","Deleting older checkpoint [results/checkpoint-3000] due to args.save_total_limit\n","Saving model checkpoint to results/checkpoint-5000\n","Configuration saved in results/checkpoint-5000/config.json\n","Model weights saved in results/checkpoint-5000/pytorch_model.bin\n","tokenizer config file saved in results/checkpoint-5000/tokenizer_config.json\n","Special tokens file saved in results/checkpoint-5000/special_tokens_map.json\n","Deleting older checkpoint [results/checkpoint-3500] due to args.save_total_limit\n","Saving model checkpoint to results/checkpoint-5500\n","Configuration saved in results/checkpoint-5500/config.json\n","Model weights saved in results/checkpoint-5500/pytorch_model.bin\n","tokenizer config file saved in results/checkpoint-5500/tokenizer_config.json\n","Special tokens file saved in results/checkpoint-5500/special_tokens_map.json\n","Deleting older checkpoint [results/checkpoint-4000] due to args.save_total_limit\n","Saving model checkpoint to results/checkpoint-6000\n","Configuration saved in results/checkpoint-6000/config.json\n","Model weights saved in results/checkpoint-6000/pytorch_model.bin\n","tokenizer config file saved in results/checkpoint-6000/tokenizer_config.json\n","Special tokens file saved in results/checkpoint-6000/special_tokens_map.json\n","Deleting older checkpoint [results/checkpoint-4500] due to args.save_total_limit\n","Saving model checkpoint to results/checkpoint-6500\n","Configuration saved in results/checkpoint-6500/config.json\n","Model weights saved in results/checkpoint-6500/pytorch_model.bin\n","tokenizer config file saved in results/checkpoint-6500/tokenizer_config.json\n","Special tokens file saved in results/checkpoint-6500/special_tokens_map.json\n","Deleting older checkpoint [results/checkpoint-5000] due to args.save_total_limit\n","Saving model checkpoint to results/checkpoint-7000\n","Configuration saved in results/checkpoint-7000/config.json\n","Model weights saved in results/checkpoint-7000/pytorch_model.bin\n","tokenizer config file saved in results/checkpoint-7000/tokenizer_config.json\n","Special tokens file saved in results/checkpoint-7000/special_tokens_map.json\n","Deleting older checkpoint [results/checkpoint-5500] due to args.save_total_limit\n","Saving model checkpoint to results/checkpoint-7500\n","Configuration saved in results/checkpoint-7500/config.json\n","Model weights saved in results/checkpoint-7500/pytorch_model.bin\n","tokenizer config file saved in results/checkpoint-7500/tokenizer_config.json\n","Special tokens file saved in results/checkpoint-7500/special_tokens_map.json\n","Deleting older checkpoint [results/checkpoint-6000] due to args.save_total_limit\n","Saving model checkpoint to results/checkpoint-8000\n","Configuration saved in results/checkpoint-8000/config.json\n","Model weights saved in results/checkpoint-8000/pytorch_model.bin\n","tokenizer config file saved in results/checkpoint-8000/tokenizer_config.json\n","Special tokens file saved in results/checkpoint-8000/special_tokens_map.json\n","Deleting older checkpoint [results/checkpoint-6500] due to args.save_total_limit\n","Saving model checkpoint to results/checkpoint-8500\n","Configuration saved in results/checkpoint-8500/config.json\n","Model weights saved in results/checkpoint-8500/pytorch_model.bin\n","tokenizer config file saved in results/checkpoint-8500/tokenizer_config.json\n","Special tokens file saved in results/checkpoint-8500/special_tokens_map.json\n","Deleting older checkpoint [results/checkpoint-7000] due to args.save_total_limit\n","Saving model checkpoint to results/checkpoint-9000\n","Configuration saved in results/checkpoint-9000/config.json\n","Model weights saved in results/checkpoint-9000/pytorch_model.bin\n","tokenizer config file saved in results/checkpoint-9000/tokenizer_config.json\n","Special tokens file saved in results/checkpoint-9000/special_tokens_map.json\n","Deleting older checkpoint [results/checkpoint-7500] due to args.save_total_limit\n","Saving model checkpoint to results/checkpoint-9500\n","Configuration saved in results/checkpoint-9500/config.json\n","Model weights saved in results/checkpoint-9500/pytorch_model.bin\n","tokenizer config file saved in results/checkpoint-9500/tokenizer_config.json\n","Special tokens file saved in results/checkpoint-9500/special_tokens_map.json\n","Deleting older checkpoint [results/checkpoint-8000] due to args.save_total_limit\n","Saving model checkpoint to results/checkpoint-10000\n","Configuration saved in results/checkpoint-10000/config.json\n","Model weights saved in results/checkpoint-10000/pytorch_model.bin\n","tokenizer config file saved in results/checkpoint-10000/tokenizer_config.json\n","Special tokens file saved in results/checkpoint-10000/special_tokens_map.json\n","Deleting older checkpoint [results/checkpoint-8500] due to args.save_total_limit\n","Saving model checkpoint to results/checkpoint-10500\n","Configuration saved in results/checkpoint-10500/config.json\n","Model weights saved in results/checkpoint-10500/pytorch_model.bin\n","tokenizer config file saved in results/checkpoint-10500/tokenizer_config.json\n","Special tokens file saved in results/checkpoint-10500/special_tokens_map.json\n","Deleting older checkpoint [results/checkpoint-9000] due to args.save_total_limit\n","Saving model checkpoint to results/checkpoint-11000\n","Configuration saved in results/checkpoint-11000/config.json\n","Model weights saved in results/checkpoint-11000/pytorch_model.bin\n","tokenizer config file saved in results/checkpoint-11000/tokenizer_config.json\n","Special tokens file saved in results/checkpoint-11000/special_tokens_map.json\n","Deleting older checkpoint [results/checkpoint-9500] due to args.save_total_limit\n","Saving model checkpoint to results/checkpoint-11500\n","Configuration saved in results/checkpoint-11500/config.json\n","Model weights saved in results/checkpoint-11500/pytorch_model.bin\n","tokenizer config file saved in results/checkpoint-11500/tokenizer_config.json\n","Special tokens file saved in results/checkpoint-11500/special_tokens_map.json\n","Deleting older checkpoint [results/checkpoint-10000] due to args.save_total_limit\n","Saving model checkpoint to results/checkpoint-12000\n","Configuration saved in results/checkpoint-12000/config.json\n","Model weights saved in results/checkpoint-12000/pytorch_model.bin\n","tokenizer config file saved in results/checkpoint-12000/tokenizer_config.json\n","Special tokens file saved in results/checkpoint-12000/special_tokens_map.json\n","Deleting older checkpoint [results/checkpoint-10500] due to args.save_total_limit\n","Saving model checkpoint to results/checkpoint-12500\n","Configuration saved in results/checkpoint-12500/config.json\n","Model weights saved in results/checkpoint-12500/pytorch_model.bin\n","tokenizer config file saved in results/checkpoint-12500/tokenizer_config.json\n","Special tokens file saved in results/checkpoint-12500/special_tokens_map.json\n","Deleting older checkpoint [results/checkpoint-11000] due to args.save_total_limit\n","Saving model checkpoint to results/checkpoint-13000\n","Configuration saved in results/checkpoint-13000/config.json\n","Model weights saved in results/checkpoint-13000/pytorch_model.bin\n","tokenizer config file saved in results/checkpoint-13000/tokenizer_config.json\n","Special tokens file saved in results/checkpoint-13000/special_tokens_map.json\n","Deleting older checkpoint [results/checkpoint-11500] due to args.save_total_limit\n","Saving model checkpoint to results/checkpoint-13500\n","Configuration saved in results/checkpoint-13500/config.json\n","Model weights saved in results/checkpoint-13500/pytorch_model.bin\n","tokenizer config file saved in results/checkpoint-13500/tokenizer_config.json\n","Special tokens file saved in results/checkpoint-13500/special_tokens_map.json\n","Deleting older checkpoint [results/checkpoint-12000] due to args.save_total_limit\n","Saving model checkpoint to results/checkpoint-14000\n","Configuration saved in results/checkpoint-14000/config.json\n","Model weights saved in results/checkpoint-14000/pytorch_model.bin\n","tokenizer config file saved in results/checkpoint-14000/tokenizer_config.json\n","Special tokens file saved in results/checkpoint-14000/special_tokens_map.json\n","Deleting older checkpoint [results/checkpoint-12500] due to args.save_total_limit\n","Saving model checkpoint to results/checkpoint-14500\n","Configuration saved in results/checkpoint-14500/config.json\n","Model weights saved in results/checkpoint-14500/pytorch_model.bin\n","tokenizer config file saved in results/checkpoint-14500/tokenizer_config.json\n","Special tokens file saved in results/checkpoint-14500/special_tokens_map.json\n","Deleting older checkpoint [results/checkpoint-13000] due to args.save_total_limit\n","Saving model checkpoint to results/checkpoint-15000\n","Configuration saved in results/checkpoint-15000/config.json\n","Model weights saved in results/checkpoint-15000/pytorch_model.bin\n","tokenizer config file saved in results/checkpoint-15000/tokenizer_config.json\n","Special tokens file saved in results/checkpoint-15000/special_tokens_map.json\n","Deleting older checkpoint [results/checkpoint-13500] due to args.save_total_limit\n","Saving model checkpoint to results/checkpoint-15500\n","Configuration saved in results/checkpoint-15500/config.json\n","Model weights saved in results/checkpoint-15500/pytorch_model.bin\n","tokenizer config file saved in results/checkpoint-15500/tokenizer_config.json\n","Special tokens file saved in results/checkpoint-15500/special_tokens_map.json\n","Deleting older checkpoint [results/checkpoint-14000] due to args.save_total_limit\n","Saving model checkpoint to results/checkpoint-16000\n","Configuration saved in results/checkpoint-16000/config.json\n","Model weights saved in results/checkpoint-16000/pytorch_model.bin\n","tokenizer config file saved in results/checkpoint-16000/tokenizer_config.json\n","Special tokens file saved in results/checkpoint-16000/special_tokens_map.json\n","Deleting older checkpoint [results/checkpoint-14500] due to args.save_total_limit\n","Saving model checkpoint to results/checkpoint-16500\n","Configuration saved in results/checkpoint-16500/config.json\n","Model weights saved in results/checkpoint-16500/pytorch_model.bin\n","tokenizer config file saved in results/checkpoint-16500/tokenizer_config.json\n","Special tokens file saved in results/checkpoint-16500/special_tokens_map.json\n","Deleting older checkpoint [results/checkpoint-15000] due to args.save_total_limit\n","Saving model checkpoint to results/checkpoint-17000\n","Configuration saved in results/checkpoint-17000/config.json\n","Model weights saved in results/checkpoint-17000/pytorch_model.bin\n","tokenizer config file saved in results/checkpoint-17000/tokenizer_config.json\n","Special tokens file saved in results/checkpoint-17000/special_tokens_map.json\n","Deleting older checkpoint [results/checkpoint-15500] due to args.save_total_limit\n","Saving model checkpoint to results/checkpoint-17500\n","Configuration saved in results/checkpoint-17500/config.json\n","Model weights saved in results/checkpoint-17500/pytorch_model.bin\n","tokenizer config file saved in results/checkpoint-17500/tokenizer_config.json\n","Special tokens file saved in results/checkpoint-17500/special_tokens_map.json\n","Deleting older checkpoint [results/checkpoint-16000] due to args.save_total_limit\n","Saving model checkpoint to results/checkpoint-18000\n","Configuration saved in results/checkpoint-18000/config.json\n","Model weights saved in results/checkpoint-18000/pytorch_model.bin\n","tokenizer config file saved in results/checkpoint-18000/tokenizer_config.json\n","Special tokens file saved in results/checkpoint-18000/special_tokens_map.json\n","Deleting older checkpoint [results/checkpoint-16500] due to args.save_total_limit\n","Saving model checkpoint to results/checkpoint-18500\n","Configuration saved in results/checkpoint-18500/config.json\n","Model weights saved in results/checkpoint-18500/pytorch_model.bin\n","tokenizer config file saved in results/checkpoint-18500/tokenizer_config.json\n","Special tokens file saved in results/checkpoint-18500/special_tokens_map.json\n","Deleting older checkpoint [results/checkpoint-17000] due to args.save_total_limit\n","Saving model checkpoint to results/checkpoint-19000\n","Configuration saved in results/checkpoint-19000/config.json\n","Model weights saved in results/checkpoint-19000/pytorch_model.bin\n","tokenizer config file saved in results/checkpoint-19000/tokenizer_config.json\n","Special tokens file saved in results/checkpoint-19000/special_tokens_map.json\n","Deleting older checkpoint [results/checkpoint-17500] due to args.save_total_limit\n","Saving model checkpoint to results/checkpoint-19500\n","Configuration saved in results/checkpoint-19500/config.json\n","Model weights saved in results/checkpoint-19500/pytorch_model.bin\n","tokenizer config file saved in results/checkpoint-19500/tokenizer_config.json\n","Special tokens file saved in results/checkpoint-19500/special_tokens_map.json\n","Deleting older checkpoint [results/checkpoint-18000] due to args.save_total_limit\n","Saving model checkpoint to results/checkpoint-20000\n","Configuration saved in results/checkpoint-20000/config.json\n","Model weights saved in results/checkpoint-20000/pytorch_model.bin\n","tokenizer config file saved in results/checkpoint-20000/tokenizer_config.json\n","Special tokens file saved in results/checkpoint-20000/special_tokens_map.json\n","Deleting older checkpoint [results/checkpoint-18500] due to args.save_total_limit\n","Saving model checkpoint to results/checkpoint-20500\n","Configuration saved in results/checkpoint-20500/config.json\n","Model weights saved in results/checkpoint-20500/pytorch_model.bin\n","tokenizer config file saved in results/checkpoint-20500/tokenizer_config.json\n","Special tokens file saved in results/checkpoint-20500/special_tokens_map.json\n","Deleting older checkpoint [results/checkpoint-19000] due to args.save_total_limit\n","Saving model checkpoint to results/checkpoint-21000\n","Configuration saved in results/checkpoint-21000/config.json\n","Model weights saved in results/checkpoint-21000/pytorch_model.bin\n","tokenizer config file saved in results/checkpoint-21000/tokenizer_config.json\n","Special tokens file saved in results/checkpoint-21000/special_tokens_map.json\n","Deleting older checkpoint [results/checkpoint-19500] due to args.save_total_limit\n","Saving model checkpoint to results/checkpoint-21500\n","Configuration saved in results/checkpoint-21500/config.json\n","Model weights saved in results/checkpoint-21500/pytorch_model.bin\n","tokenizer config file saved in results/checkpoint-21500/tokenizer_config.json\n","Special tokens file saved in results/checkpoint-21500/special_tokens_map.json\n","Deleting older checkpoint [results/checkpoint-20000] due to args.save_total_limit\n","Saving model checkpoint to results/checkpoint-22000\n","Configuration saved in results/checkpoint-22000/config.json\n","Model weights saved in results/checkpoint-22000/pytorch_model.bin\n","tokenizer config file saved in results/checkpoint-22000/tokenizer_config.json\n","Special tokens file saved in results/checkpoint-22000/special_tokens_map.json\n","Deleting older checkpoint [results/checkpoint-20500] due to args.save_total_limit\n","Saving model checkpoint to results/checkpoint-22500\n","Configuration saved in results/checkpoint-22500/config.json\n","Model weights saved in results/checkpoint-22500/pytorch_model.bin\n","tokenizer config file saved in results/checkpoint-22500/tokenizer_config.json\n","Special tokens file saved in results/checkpoint-22500/special_tokens_map.json\n","Deleting older checkpoint [results/checkpoint-21000] due to args.save_total_limit\n","Saving model checkpoint to results/checkpoint-23000\n","Configuration saved in results/checkpoint-23000/config.json\n","Model weights saved in results/checkpoint-23000/pytorch_model.bin\n","tokenizer config file saved in results/checkpoint-23000/tokenizer_config.json\n","Special tokens file saved in results/checkpoint-23000/special_tokens_map.json\n","Deleting older checkpoint [results/checkpoint-21500] due to args.save_total_limit\n","Saving model checkpoint to results/checkpoint-23500\n","Configuration saved in results/checkpoint-23500/config.json\n","Model weights saved in results/checkpoint-23500/pytorch_model.bin\n","tokenizer config file saved in results/checkpoint-23500/tokenizer_config.json\n","Special tokens file saved in results/checkpoint-23500/special_tokens_map.json\n","Deleting older checkpoint [results/checkpoint-22000] due to args.save_total_limit\n","Saving model checkpoint to results/checkpoint-24000\n","Configuration saved in results/checkpoint-24000/config.json\n","Model weights saved in results/checkpoint-24000/pytorch_model.bin\n","tokenizer config file saved in results/checkpoint-24000/tokenizer_config.json\n","Special tokens file saved in results/checkpoint-24000/special_tokens_map.json\n","Deleting older checkpoint [results/checkpoint-22500] due to args.save_total_limit\n","Saving model checkpoint to results/checkpoint-24500\n","Configuration saved in results/checkpoint-24500/config.json\n","Model weights saved in results/checkpoint-24500/pytorch_model.bin\n","tokenizer config file saved in results/checkpoint-24500/tokenizer_config.json\n","Special tokens file saved in results/checkpoint-24500/special_tokens_map.json\n","Deleting older checkpoint [results/checkpoint-23000] due to args.save_total_limit\n","Saving model checkpoint to results/checkpoint-25000\n","Configuration saved in results/checkpoint-25000/config.json\n","Model weights saved in results/checkpoint-25000/pytorch_model.bin\n","tokenizer config file saved in results/checkpoint-25000/tokenizer_config.json\n","Special tokens file saved in results/checkpoint-25000/special_tokens_map.json\n","Deleting older checkpoint [results/checkpoint-23500] due to args.save_total_limit\n","Saving model checkpoint to results/checkpoint-25500\n","Configuration saved in results/checkpoint-25500/config.json\n","Model weights saved in results/checkpoint-25500/pytorch_model.bin\n","tokenizer config file saved in results/checkpoint-25500/tokenizer_config.json\n","Special tokens file saved in results/checkpoint-25500/special_tokens_map.json\n","Deleting older checkpoint [results/checkpoint-24000] due to args.save_total_limit\n","Saving model checkpoint to results/checkpoint-26000\n","Configuration saved in results/checkpoint-26000/config.json\n","Model weights saved in results/checkpoint-26000/pytorch_model.bin\n","tokenizer config file saved in results/checkpoint-26000/tokenizer_config.json\n","Special tokens file saved in results/checkpoint-26000/special_tokens_map.json\n","Deleting older checkpoint [results/checkpoint-24500] due to args.save_total_limit\n","Saving model checkpoint to results/checkpoint-26500\n","Configuration saved in results/checkpoint-26500/config.json\n","Model weights saved in results/checkpoint-26500/pytorch_model.bin\n","tokenizer config file saved in results/checkpoint-26500/tokenizer_config.json\n","Special tokens file saved in results/checkpoint-26500/special_tokens_map.json\n","Deleting older checkpoint [results/checkpoint-25000] due to args.save_total_limit\n","Saving model checkpoint to results/checkpoint-27000\n","Configuration saved in results/checkpoint-27000/config.json\n","Model weights saved in results/checkpoint-27000/pytorch_model.bin\n","tokenizer config file saved in results/checkpoint-27000/tokenizer_config.json\n","Special tokens file saved in results/checkpoint-27000/special_tokens_map.json\n","Deleting older checkpoint [results/checkpoint-25500] due to args.save_total_limit\n","Saving model checkpoint to results/checkpoint-27500\n","Configuration saved in results/checkpoint-27500/config.json\n","Model weights saved in results/checkpoint-27500/pytorch_model.bin\n","tokenizer config file saved in results/checkpoint-27500/tokenizer_config.json\n","Special tokens file saved in results/checkpoint-27500/special_tokens_map.json\n","Deleting older checkpoint [results/checkpoint-26000] due to args.save_total_limit\n","Saving model checkpoint to results/checkpoint-28000\n","Configuration saved in results/checkpoint-28000/config.json\n","Model weights saved in results/checkpoint-28000/pytorch_model.bin\n","tokenizer config file saved in results/checkpoint-28000/tokenizer_config.json\n","Special tokens file saved in results/checkpoint-28000/special_tokens_map.json\n","Deleting older checkpoint [results/checkpoint-26500] due to args.save_total_limit\n","Saving model checkpoint to results/checkpoint-28500\n","Configuration saved in results/checkpoint-28500/config.json\n","Model weights saved in results/checkpoint-28500/pytorch_model.bin\n","tokenizer config file saved in results/checkpoint-28500/tokenizer_config.json\n","Special tokens file saved in results/checkpoint-28500/special_tokens_map.json\n","Deleting older checkpoint [results/checkpoint-27000] due to args.save_total_limit\n","Saving model checkpoint to results/checkpoint-29000\n","Configuration saved in results/checkpoint-29000/config.json\n","Model weights saved in results/checkpoint-29000/pytorch_model.bin\n","tokenizer config file saved in results/checkpoint-29000/tokenizer_config.json\n","Special tokens file saved in results/checkpoint-29000/special_tokens_map.json\n","Deleting older checkpoint [results/checkpoint-27500] due to args.save_total_limit\n","Saving model checkpoint to results/checkpoint-29500\n","Configuration saved in results/checkpoint-29500/config.json\n","Model weights saved in results/checkpoint-29500/pytorch_model.bin\n","tokenizer config file saved in results/checkpoint-29500/tokenizer_config.json\n","Special tokens file saved in results/checkpoint-29500/special_tokens_map.json\n","Deleting older checkpoint [results/checkpoint-28000] due to args.save_total_limit\n","Saving model checkpoint to results/checkpoint-30000\n","Configuration saved in results/checkpoint-30000/config.json\n","Model weights saved in results/checkpoint-30000/pytorch_model.bin\n","tokenizer config file saved in results/checkpoint-30000/tokenizer_config.json\n","Special tokens file saved in results/checkpoint-30000/special_tokens_map.json\n","Deleting older checkpoint [results/checkpoint-28500] due to args.save_total_limit\n","Saving model checkpoint to results/checkpoint-30500\n","Configuration saved in results/checkpoint-30500/config.json\n","Model weights saved in results/checkpoint-30500/pytorch_model.bin\n","tokenizer config file saved in results/checkpoint-30500/tokenizer_config.json\n","Special tokens file saved in results/checkpoint-30500/special_tokens_map.json\n","Deleting older checkpoint [results/checkpoint-29000] due to args.save_total_limit\n","Saving model checkpoint to results/checkpoint-31000\n","Configuration saved in results/checkpoint-31000/config.json\n","Model weights saved in results/checkpoint-31000/pytorch_model.bin\n","tokenizer config file saved in results/checkpoint-31000/tokenizer_config.json\n","Special tokens file saved in results/checkpoint-31000/special_tokens_map.json\n","Deleting older checkpoint [results/checkpoint-29500] due to args.save_total_limit\n","Saving model checkpoint to results/checkpoint-31500\n","Configuration saved in results/checkpoint-31500/config.json\n","Model weights saved in results/checkpoint-31500/pytorch_model.bin\n","tokenizer config file saved in results/checkpoint-31500/tokenizer_config.json\n","Special tokens file saved in results/checkpoint-31500/special_tokens_map.json\n","Deleting older checkpoint [results/checkpoint-30000] due to args.save_total_limit\n","Saving model checkpoint to results/checkpoint-32000\n","Configuration saved in results/checkpoint-32000/config.json\n","Model weights saved in results/checkpoint-32000/pytorch_model.bin\n","tokenizer config file saved in results/checkpoint-32000/tokenizer_config.json\n","Special tokens file saved in results/checkpoint-32000/special_tokens_map.json\n","Deleting older checkpoint [results/checkpoint-30500] due to args.save_total_limit\n","Saving model checkpoint to results/checkpoint-32500\n","Configuration saved in results/checkpoint-32500/config.json\n","Model weights saved in results/checkpoint-32500/pytorch_model.bin\n","tokenizer config file saved in results/checkpoint-32500/tokenizer_config.json\n","Special tokens file saved in results/checkpoint-32500/special_tokens_map.json\n","Deleting older checkpoint [results/checkpoint-31000] due to args.save_total_limit\n","Saving model checkpoint to results/checkpoint-33000\n","Configuration saved in results/checkpoint-33000/config.json\n","Model weights saved in results/checkpoint-33000/pytorch_model.bin\n","tokenizer config file saved in results/checkpoint-33000/tokenizer_config.json\n","Special tokens file saved in results/checkpoint-33000/special_tokens_map.json\n","Deleting older checkpoint [results/checkpoint-31500] due to args.save_total_limit\n","Saving model checkpoint to results/checkpoint-33500\n","Configuration saved in results/checkpoint-33500/config.json\n","Model weights saved in results/checkpoint-33500/pytorch_model.bin\n","tokenizer config file saved in results/checkpoint-33500/tokenizer_config.json\n","Special tokens file saved in results/checkpoint-33500/special_tokens_map.json\n","Deleting older checkpoint [results/checkpoint-32000] due to args.save_total_limit\n","Saving model checkpoint to results/checkpoint-34000\n","Configuration saved in results/checkpoint-34000/config.json\n","Model weights saved in results/checkpoint-34000/pytorch_model.bin\n","tokenizer config file saved in results/checkpoint-34000/tokenizer_config.json\n","Special tokens file saved in results/checkpoint-34000/special_tokens_map.json\n","Deleting older checkpoint [results/checkpoint-32500] due to args.save_total_limit\n","Saving model checkpoint to results/checkpoint-34500\n","Configuration saved in results/checkpoint-34500/config.json\n","Model weights saved in results/checkpoint-34500/pytorch_model.bin\n","tokenizer config file saved in results/checkpoint-34500/tokenizer_config.json\n","Special tokens file saved in results/checkpoint-34500/special_tokens_map.json\n","Deleting older checkpoint [results/checkpoint-33000] due to args.save_total_limit\n","Saving model checkpoint to results/checkpoint-35000\n","Configuration saved in results/checkpoint-35000/config.json\n","Model weights saved in results/checkpoint-35000/pytorch_model.bin\n","tokenizer config file saved in results/checkpoint-35000/tokenizer_config.json\n","Special tokens file saved in results/checkpoint-35000/special_tokens_map.json\n","Deleting older checkpoint [results/checkpoint-33500] due to args.save_total_limit\n","Saving model checkpoint to results/checkpoint-35500\n","Configuration saved in results/checkpoint-35500/config.json\n","Model weights saved in results/checkpoint-35500/pytorch_model.bin\n","tokenizer config file saved in results/checkpoint-35500/tokenizer_config.json\n","Special tokens file saved in results/checkpoint-35500/special_tokens_map.json\n","Deleting older checkpoint [results/checkpoint-34000] due to args.save_total_limit\n","Saving model checkpoint to results/checkpoint-36000\n","Configuration saved in results/checkpoint-36000/config.json\n","Model weights saved in results/checkpoint-36000/pytorch_model.bin\n","tokenizer config file saved in results/checkpoint-36000/tokenizer_config.json\n","Special tokens file saved in results/checkpoint-36000/special_tokens_map.json\n","Deleting older checkpoint [results/checkpoint-34500] due to args.save_total_limit\n","Saving model checkpoint to results/checkpoint-36500\n","Configuration saved in results/checkpoint-36500/config.json\n","Model weights saved in results/checkpoint-36500/pytorch_model.bin\n","tokenizer config file saved in results/checkpoint-36500/tokenizer_config.json\n","Special tokens file saved in results/checkpoint-36500/special_tokens_map.json\n","Deleting older checkpoint [results/checkpoint-35000] due to args.save_total_limit\n","Saving model checkpoint to results/checkpoint-37000\n","Configuration saved in results/checkpoint-37000/config.json\n","Model weights saved in results/checkpoint-37000/pytorch_model.bin\n","tokenizer config file saved in results/checkpoint-37000/tokenizer_config.json\n","Special tokens file saved in results/checkpoint-37000/special_tokens_map.json\n","Deleting older checkpoint [results/checkpoint-35500] due to args.save_total_limit\n","Saving model checkpoint to results/checkpoint-37500\n","Configuration saved in results/checkpoint-37500/config.json\n","Model weights saved in results/checkpoint-37500/pytorch_model.bin\n","tokenizer config file saved in results/checkpoint-37500/tokenizer_config.json\n","Special tokens file saved in results/checkpoint-37500/special_tokens_map.json\n","Deleting older checkpoint [results/checkpoint-36000] due to args.save_total_limit\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n"]},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=37904, training_loss=2.3000644765960963, metrics={'train_runtime': 22212.5592, 'train_samples_per_second': 6.825, 'train_steps_per_second': 1.706, 'total_flos': 1.0950492236965478e+17, 'train_loss': 2.3000644765960963, 'epoch': 8.0})"]},"metadata":{},"execution_count":17}],"source":["#%%wandb\n","# uncomment to display Wandb charts\n","\n","trainer.train()"]},{"cell_type":"markdown","metadata":{"id":"V3C-4SfOPssY"},"source":["Evaluate after fine-tuning"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"_-QyUtCRH9DO","colab":{"base_uri":"https://localhost:8080/","height":263},"executionInfo":{"status":"ok","timestamp":1650626277424,"user_tz":300,"elapsed":50867,"user":{"displayName":"Jose Talavera","userId":"03337362936427322220"}},"outputId":"9b432d6c-b160-44ef-8ba3-58ec3b2cccf1"},"outputs":[{"output_type":"stream","name":"stderr","text":["***** Running Evaluation *****\n","  Num examples = 100\n","  Batch size = 4\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='50' max='25' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [25/25 6:11:59]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["{'epoch': 8.0,\n"," 'eval_gen_len': 60.33,\n"," 'eval_loss': 2.868989944458008,\n"," 'eval_rouge1': 62.0644,\n"," 'eval_rouge2': 44.7528,\n"," 'eval_rougeL': 53.5879,\n"," 'eval_rougeLsum': 55.6217,\n"," 'eval_runtime': 50.8769,\n"," 'eval_samples_per_second': 1.966,\n"," 'eval_steps_per_second': 0.491}"]},"metadata":{},"execution_count":18}],"source":["trainer.evaluate()"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"ClRTrG2ETUm3","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["eec6883e69a04929ae64480c5878edb5","69bfee2729234d63b8c93bebba5f8ec4","7ebc44e72e634f1e9ebea7939f363d88","39be6a0423e84c48a6fddd21e1e26088","ae18902ceb9748a8b85958f33f7d6d0d","9a6bdfb4a9d8494ba41927e5b539c831","e2079a8a09064839977ed895e2fcf210","d6ca52ce7816482a85dc62563b7a5e02"]},"executionInfo":{"status":"ok","timestamp":1650626282087,"user_tz":300,"elapsed":4676,"user":{"displayName":"Jose Talavera","userId":"03337362936427322220"}},"outputId":"2ed51f34-462d-4735-b2fb-1f32f8fee64b"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eec6883e69a04929ae64480c5878edb5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/gen_len</td><td>▁█</td></tr><tr><td>eval/loss</td><td>█▁</td></tr><tr><td>eval/rouge1</td><td>▁█</td></tr><tr><td>eval/rouge2</td><td>▁█</td></tr><tr><td>eval/rougeL</td><td>▁█</td></tr><tr><td>eval/rougeLsum</td><td>▁█</td></tr><tr><td>eval/runtime</td><td>█▁</td></tr><tr><td>eval/samples_per_second</td><td>▁█</td></tr><tr><td>eval/steps_per_second</td><td>▁█</td></tr><tr><td>train/epoch</td><td>▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>train/learning_rate</td><td>▂▄▅▇███▇▇▇▇▆▆▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▂▂▂▂▁▁▁</td></tr><tr><td>train/loss</td><td>█▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/gen_len</td><td>60.33</td></tr><tr><td>eval/loss</td><td>2.86899</td></tr><tr><td>eval/rouge1</td><td>62.0644</td></tr><tr><td>eval/rouge2</td><td>44.7528</td></tr><tr><td>eval/rougeL</td><td>53.5879</td></tr><tr><td>eval/rougeLsum</td><td>55.6217</td></tr><tr><td>eval/runtime</td><td>50.8769</td></tr><tr><td>eval/samples_per_second</td><td>1.966</td></tr><tr><td>eval/steps_per_second</td><td>0.491</td></tr><tr><td>train/epoch</td><td>8.0</td></tr><tr><td>train/global_step</td><td>37904</td></tr><tr><td>train/learning_rate</td><td>1e-05</td></tr><tr><td>train/loss</td><td>1.7588</td></tr><tr><td>train/total_flos</td><td>1.0950492236965478e+17</td></tr><tr><td>train/train_loss</td><td>2.30006</td></tr><tr><td>train/train_runtime</td><td>22212.5592</td></tr><tr><td>train/train_samples_per_second</td><td>6.825</td></tr><tr><td>train/train_steps_per_second</td><td>1.706</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Synced <strong style=\"color:#cdcd00\">logical-tree-15</strong>: <a href=\"https://wandb.ai/bigbam/distill-pegasus_billsum_FT/runs/2rihcx5x\" target=\"_blank\">https://wandb.ai/bigbam/distill-pegasus_billsum_FT/runs/2rihcx5x</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20220422_050552-2rihcx5x/logs</code>"]},"metadata":{}}],"source":["if WANDB_INTEGRATION:\n","    wandb_run.finish()"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"xpfby90xSSiY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650626282087,"user_tz":300,"elapsed":10,"user":{"displayName":"Jose Talavera","userId":"03337362936427322220"}},"outputId":"bf41b425-be50-49d3-c176-441c56a039fc"},"outputs":[{"output_type":"stream","name":"stdout","text":["Fri Apr 22 11:18:02 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   65C    P0    45W / 250W |  13731MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","+-----------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi"]},{"cell_type":"markdown","metadata":{"id":"-gSLVnGL9bol"},"source":["## Evaluation\n","\n","---"]},{"cell_type":"markdown","metadata":{"id":"hDwj24cfILS6"},"source":["**Generate summaries from the fine-tuned model and compare them with those generated from the original, pre-trained one.**"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"NV64-XdA_rOM","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"error","timestamp":1650626373550,"user_tz":300,"elapsed":91467,"user":{"displayName":"Jose Talavera","userId":"03337362936427322220"}},"outputId":"c8b4cab9-a9c9-45f0-bed2-91986f3824ba"},"outputs":[{"output_type":"stream","name":"stderr","text":["loading configuration file https://huggingface.co/google/pegasus-xsum/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/f8db793080242073e939bf4bc066830a677ca5e1c2d3aa1fc2a79fe733ccf3c9.149318290a6d6f03f34bb735260994b16b4a7c8609973a4abc8e9315c7c5797c\n","Model config PegasusConfig {\n","  \"_name_or_path\": \"google/pegasus-xsum\",\n","  \"activation_dropout\": 0.1,\n","  \"activation_function\": \"relu\",\n","  \"add_bias_logits\": false,\n","  \"add_final_layer_norm\": true,\n","  \"architectures\": [\n","    \"PegasusForConditionalGeneration\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classif_dropout\": 0.0,\n","  \"classifier_dropout\": 0.0,\n","  \"d_model\": 1024,\n","  \"decoder_attention_heads\": 16,\n","  \"decoder_ffn_dim\": 4096,\n","  \"decoder_layerdrop\": 0.0,\n","  \"decoder_layers\": 16,\n","  \"decoder_start_token_id\": 0,\n","  \"do_blenderbot_90_layernorm\": false,\n","  \"dropout\": 0.1,\n","  \"encoder_attention_heads\": 16,\n","  \"encoder_ffn_dim\": 4096,\n","  \"encoder_layerdrop\": 0.0,\n","  \"encoder_layers\": 16,\n","  \"eos_token_id\": 1,\n","  \"extra_pos_embeddings\": 0,\n","  \"force_bos_token_to_be_generated\": false,\n","  \"forced_eos_token_id\": 1,\n","  \"gradient_checkpointing\": false,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"length_penalty\": 0.6,\n","  \"max_length\": 64,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"pegasus\",\n","  \"normalize_before\": true,\n","  \"normalize_embedding\": false,\n","  \"num_beams\": 8,\n","  \"num_hidden_layers\": 16,\n","  \"pad_token_id\": 0,\n","  \"scale_embedding\": true,\n","  \"static_position_embeddings\": true,\n","  \"transformers_version\": \"4.18.0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 96103\n","}\n","\n","loading weights file https://huggingface.co/google/pegasus-xsum/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/ddcc1cff87fee162e2905d3466807fe77fd58b88f3e90cf30824032b121396f0.eb12ff56dff38f793b50dd1ead8bacb82b33aa7c9cb713aa0471bc2fdd353c9e\n","All model checkpoint weights were used when initializing PegasusForConditionalGeneration.\n","\n","All the weights of PegasusForConditionalGeneration were initialized from the model checkpoint at google/pegasus-xsum.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use PegasusForConditionalGeneration for predictions without further training.\n"]},{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-21-73b64e87f602>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0msummaries_before_tuning\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_before_tuning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0msummaries_after_tuning\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-21-73b64e87f602>\u001b[0m in \u001b[0;36mgenerate_summary\u001b[0;34m(test_samples, model)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0minput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mattention_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0moutput_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_str\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/generation_utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, max_length, min_length, do_sample, early_stopping, num_beams, temperature, top_k, top_p, typical_p, repetition_penalty, bad_words_ids, force_words_ids, bos_token_id, pad_token_id, eos_token_id, length_penalty, no_repeat_ngram_size, encoder_no_repeat_ngram_size, num_return_sequences, max_time, max_new_tokens, decoder_start_token_id, use_cache, num_beam_groups, diversity_penalty, prefix_allowed_tokens_fn, logits_processor, stopping_criteria, constraints, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, forced_bos_token_id, forced_eos_token_id, remove_invalid_values, synced_gpus, exponential_decay_length_penalty, **model_kwargs)\u001b[0m\n\u001b[1;32m   1323\u001b[0m                 \u001b[0mreturn_dict_in_generate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict_in_generate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m                 \u001b[0msynced_gpus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynced_gpus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1325\u001b[0;31m                 \u001b[0;34m**\u001b[0m\u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1326\u001b[0m             )\n\u001b[1;32m   1327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/generation_utils.py\u001b[0m in \u001b[0;36mbeam_search\u001b[0;34m(self, input_ids, beam_scorer, logits_processor, stopping_criteria, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[1;32m   2160\u001b[0m                 \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2161\u001b[0m                 \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2162\u001b[0;31m                 \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2163\u001b[0m             )\n\u001b[1;32m   2164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/pegasus/modeling_pegasus.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1405\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1406\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1408\u001b[0m         )\n\u001b[1;32m   1409\u001b[0m         \u001b[0mlm_logits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlm_head\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinal_logits_bias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/pegasus/modeling_pegasus.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1259\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1260\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1261\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1262\u001b[0m         )\n\u001b[1;32m   1263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/pegasus/modeling_pegasus.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, head_mask, cross_attn_head_mask, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1092\u001b[0m                     \u001b[0mpast_key_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1093\u001b[0m                     \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1094\u001b[0;31m                     \u001b[0muse_cache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_cache\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1095\u001b[0m                 )\n\u001b[1;32m   1096\u001b[0m             \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/pegasus/modeling_pegasus.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, encoder_hidden_states, encoder_attention_mask, layer_head_mask, cross_attn_layer_head_mask, past_key_value, output_attentions, use_cache)\u001b[0m\n\u001b[1;32m    425\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m             \u001b[0mlayer_head_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlayer_head_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m         )\n\u001b[1;32m    429\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/pegasus/modeling_pegasus.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, key_value_states, past_key_value, attention_mask, layer_head_mask, output_attentions)\u001b[0m\n\u001b[1;32m    208\u001b[0m             \u001b[0mvalue_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbsz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m             \u001b[0mkey_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpast_key_value\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey_states\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m             \u001b[0mvalue_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpast_key_value\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue_states\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m             \u001b[0;31m# self_attention\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 18.00 MiB (GPU 0; 15.90 GiB total capacity; 14.25 GiB already allocated; 11.75 MiB free; 14.78 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"]}],"source":["def generate_summary(test_samples, model):\n","    inputs = tokenizer(\n","        test_samples[\"text\"],\n","        padding=\"max_length\",\n","        truncation=True,\n","        max_length=encoder_max_length,\n","        return_tensors=\"pt\",\n","    )\n","    input_ids = inputs.input_ids.to(model.device)\n","    attention_mask = inputs.attention_mask.to(model.device)\n","    outputs = model.generate(input_ids, attention_mask=attention_mask)\n","    output_str = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n","    return outputs, output_str\n","\n","\n","model_before_tuning = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n","\n","test_samples = validation_data_txt.select(range(16))\n","\n","summaries_before_tuning = generate_summary(test_samples, model_before_tuning)[1]\n","summaries_after_tuning = generate_summary(test_samples, model)[1]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"D7IPtJLjCcmS","executionInfo":{"status":"aborted","timestamp":1650626372808,"user_tz":300,"elapsed":531,"user":{"displayName":"Jose Talavera","userId":"03337362936427322220"}}},"outputs":[],"source":["print(\n","    tabulate(\n","        zip(\n","            range(len(summaries_after_tuning)),\n","            summaries_after_tuning,\n","            summaries_before_tuning,\n","        ),\n","        headers=[\"Id\", \"Summary after\", \"Summary before\"],\n","    )\n",")\n","print(\"\\nTarget summaries:\\n\")\n","print(\n","    tabulate(list(enumerate(test_samples[\"text\"])), headers=[\"Id\", \"Target summary\"])\n",")\n","print(\"\\nSource documents:\\n\")\n","print(tabulate(list(enumerate(test_samples[\"summary\"])), headers=[\"Id\", \"Document\"]))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dLiP9Q5QWg-A","executionInfo":{"status":"aborted","timestamp":1650626372809,"user_tz":300,"elapsed":532,"user":{"displayName":"Jose Talavera","userId":"03337362936427322220"}}},"outputs":[],"source":["from google.colab import files\n","torch.save(model.state_dict(), 'Pegasus_BillSum_Long.pth')\n","\n","# download checkpoint file\n","files.download('Pegasus_BillSum_Long.pth')"]},{"cell_type":"code","source":[""],"metadata":{"id":"R_ucIrIAo6J_","executionInfo":{"status":"aborted","timestamp":1650626372810,"user_tz":300,"elapsed":533,"user":{"displayName":"Jose Talavera","userId":"03337362936427322220"}}},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"background_execution":"on","collapsed_sections":[],"machine_shape":"hm","name":"Pegasus_BillSum_FT_Long.ipynb","provenance":[{"file_id":"10ssxMVREVpqhTY1JC73SAaWEgakZOxC0","timestamp":1647118585184},{"file_id":"1NvVBgDED8vinTcBGUP0xT1quUyEqp8aP","timestamp":1635891308251},{"file_id":"https://github.com/elsanns/xai-nlp-notebooks/blob/master/fine_tune_bart_summarization_two_langs.ipynb","timestamp":1635184568547}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"82f331884b5140a19b3fa2cac92f850c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_badb6456430a419e98d4d6a9a012b172","IPY_MODEL_9604c9a5d9d14f9ebdf1906bcd6d5fe2","IPY_MODEL_033a2ef8b4ba4154abc9520edf516dfe"],"layout":"IPY_MODEL_1de9f76982d9425e92d659b5ee1ec1cd"}},"badb6456430a419e98d4d6a9a012b172":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9805721a4250478faa315e3e235e9cbb","placeholder":"​","style":"IPY_MODEL_3d12bf7360004e0d8380ddb75019b58b","value":"100%"}},"9604c9a5d9d14f9ebdf1906bcd6d5fe2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d1dcc1fc510447b487a4c6c0c3bb430e","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1114696de2cb475f842ef761483f652a","value":1}},"033a2ef8b4ba4154abc9520edf516dfe":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5c5e5287edf44a55a1af8a7170bdf00c","placeholder":"​","style":"IPY_MODEL_fd77d25c86d943a6990c5d49166ee95e","value":" 1/1 [00:00&lt;00:00,  3.65ba/s]"}},"1de9f76982d9425e92d659b5ee1ec1cd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9805721a4250478faa315e3e235e9cbb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3d12bf7360004e0d8380ddb75019b58b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d1dcc1fc510447b487a4c6c0c3bb430e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1114696de2cb475f842ef761483f652a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5c5e5287edf44a55a1af8a7170bdf00c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fd77d25c86d943a6990c5d49166ee95e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"eec6883e69a04929ae64480c5878edb5":{"model_module":"@jupyter-widgets/controls","model_name":"VBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_69bfee2729234d63b8c93bebba5f8ec4","IPY_MODEL_7ebc44e72e634f1e9ebea7939f363d88"],"layout":"IPY_MODEL_39be6a0423e84c48a6fddd21e1e26088"}},"69bfee2729234d63b8c93bebba5f8ec4":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ae18902ceb9748a8b85958f33f7d6d0d","placeholder":"​","style":"IPY_MODEL_9a6bdfb4a9d8494ba41927e5b539c831","value":"1.541 MB of 1.541 MB uploaded (0.000 MB deduped)\r"}},"7ebc44e72e634f1e9ebea7939f363d88":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_e2079a8a09064839977ed895e2fcf210","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d6ca52ce7816482a85dc62563b7a5e02","value":1}},"39be6a0423e84c48a6fddd21e1e26088":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ae18902ceb9748a8b85958f33f7d6d0d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9a6bdfb4a9d8494ba41927e5b539c831":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e2079a8a09064839977ed895e2fcf210":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d6ca52ce7816482a85dc62563b7a5e02":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}}}}},"nbformat":4,"nbformat_minor":0}